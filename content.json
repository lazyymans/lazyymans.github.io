[{"title":"Spring-Cloud微服务架构（四）服务网关","date":"2018-05-09T15:49:32.000Z","path":"2018/05/09/Spring-Cloud微服务架构（四）服务网关/","text":"之前，我们已经初步完成了一个简易版的微服务分布式系统了。我们使用Spring Cloud Netflix中的Eureka实现了服务注册中心以及服务注册与发现；而服务间通过Ribbon或Feign实现服务的消费以及均衡负载；为了使得服务集群更为健壮，使用Hystrix的融断机制来避免在微服务架构中个别服务出现异常时引起的故障蔓延。 在该架构中，我们的服务集群包含：内部服务Pay Server和Provider Server，他们都会注册与订阅服务至Eureka Server，这里还有个对外提供的一个服务，这个服务通过负载均衡提供调用服务Pay Server和服务Provider Server的方法，本文我们把焦点聚集在对外服务这块，这样的实现是否合理，或者是否有更好的实现方式呢？ 先来说说这样架构需要做的一些事儿以及存在的不足： 首先，破坏了服务无状态特点。为了保证对外服务的安全性，我们需要实现对服务访问的权限控制，而开放服务的权限控制机制将会贯穿并污染整个开放服务的业务逻辑，这会带来的最直接问题是，破坏了服务集群中REST API无状态的特点。从具体开发和测试的角度来说，在工作中除了要考虑实际的业务逻辑之外，还需要额外可续对接口访问的控制处理。 其次，无法直接复用既有接口。当我们需要对一个即有的集群内访问接口，实现外部服务访问时，我们不得不通过在原有接口上增加校验逻辑，或增加一个代理调用来实现权限控制，无法直接复用原有的接口。 面对类似上面的问题，我们要如何解决呢？下面进入本文的正题：服务网关！ 为了解决上面这些问题，我们需要将权限控制这样的东西从我们的服务单元中抽离出去，而最适合这些逻辑的地方就是处于对外访问最前端的地方，我们需要一个更强大一些的均衡负载器，它就是本文将来介绍的：服务网关。 服务网关是微服务架构中一个不可或缺的部分。通过服务网关统一向外系统提供REST API的过程中，除了具备服务路由、均衡负载功能之外，它还具备了权限控制等功能。Spring Cloud Netflix中的Zuul就担任了这样的一个角色，为微服务架构提供了前门保护的作用，同时将权限控制这些较重的非业务逻辑内容迁移到服务路由层面，使得服务集群主体能够具备更高的可复用性和可测试性。 下面我们通过实例例子来使用一下Zuul来作为服务的路有功能。 开始使用Zuul1、创建一个Web Gateway服务，引入pom.xml 所需要的依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.blog&lt;/groupId&gt; &lt;artifactId&gt;web-gateway&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;web-gateway&lt;/name&gt; &lt;description&gt;web-gateway&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RC1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- zuul --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务消费者 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 2、在主应用类上开启zuul，加入注解@EnableZuulProxy 123456789101112131415161718@EnableZuulProxy@EnableEurekaClient@SpringCloudApplicationpublic class WebGatewayApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate()&#123; SimpleClientHttpRequestFactory simpleClientHttpRequestFactory = new SimpleClientHttpRequestFactory (); simpleClientHttpRequestFactory.setConnectTimeout(10000); simpleClientHttpRequestFactory.setReadTimeout(10000); return new RestTemplate(simpleClientHttpRequestFactory); &#125; public static void main(String[] args) &#123; SpringApplication.run(WebGatewayApplication.class, args); &#125;&#125; 3、在application.yml中配置zuul 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748server: port: 9400eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: web-gatewaypay-server: ribbon:# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮调 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRuleprovider-server: ribbon:# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮调 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule##断路器 将 hystrix 的超时时间设置成 60000 毫秒（60秒）hystrix: command: default: execution: timeout: enabled: false isolation: thread: timeoutInMilliseconds: 60000# zuulzuul: host: socket-timeout-millis: 60000 connect-timeout-millis: 60000 routes: api-pay: path: /pay/**# url: http://localhost:9200/ serviceId: pay-server api-provider: path: /provider/** serviceId: provider-server zuul 配置介绍 服务路由通过服务路由的功能，我们在对外提供服务的时候，只需要通过暴露Zuul中配置的调用地址就可以让调用方统一的来访问我们的服务，而不需要了解具体提供服务的主机信息了。 在Zuul中提供了两种映射方式： 通过url直接映射，我们可以如下配置：（实际项目中不推荐使用） 123456789101112# zuulzuul: host: socket-timeout-millis: 60000 connect-timeout-millis: 60000 routes: api-pay: path: /pay/** url: http://localhost:9200/ api-provider: path: /provider/** url: http://localhost:9300/ 该配置中将所有的/pay/**的访问映射到http://localhost:9200/上，也就是说当我们访问http://localhost:9400/pay/api/pay/testPay的时候，Zuul会将该请求路由到：http://localhost:9200/api/pay/testPay上。 其中，配置属性zuul.routes.api-pay.path中的api-pay部分为路由的名字，可以任意定义，但是一组映射关系的path和url要相同，下面讲serviceId时候也是如此。 通过serviceId映射（推荐配置） 通过url映射的方式对于Zuul来说，并不是特别友好，Zuul需要知道我们所有为服务的地址，才能完成所有的映射配置。而实际上，我们在实现微服务架构是，服务名与服务实例地址的关系在Eureka Server中已经存在了，所以只需要将Zuul注册到Eureka Server上去发现其他服务，我们就可以实现对serviceId的映射。例如，我们可以如下配置： 123456789101112# zuulzuul: host: socket-timeout-millis: 60000 connect-timeout-millis: 60000 routes: api-pay: path: /pay/** serviceId: pay-server api-provider: path: /provider/** serviceId: provider-server 这里我们说明下为什么推荐使用这种配置。当我们整个系统运行起来的时候，肯定会把我们一个个的服务集群化，这样我们使用直接的url映射，将无法进行负载均衡。也就容易出现某一台服务器的负载过高，而其他服务器空闲，资源浪费。 下面，我们就来演示一下效果，分别启动Eureka Server、Pay Server、Provider Server、Web Gateway四个服务。 然后我们同过服务网关来访问Pay Server、Provider Server，根据配置的映射关系，分别访问下面的url http://localhost:9400/pay/api/pay/testPay：通过serviceId映射访问Pay Server中的testPay服务 http://localhost:9400/provider/api/provider/testProvider：通过serviceId映射访问Provider Server中的testProvider服务 访问结果 服务过滤在完成了服务路由之后，我们对外开放服务还需要一些安全措施来保护客户端只能访问它应该访问到的资源。所以我们需要利用Zuul的过滤器来实现我们对外服务的安全控制。 在服务网关中定义过滤器只需要继承ZuulFilter抽象类实现其定义的四个抽象函数就可对请求进行拦截与过滤。 比如下面的例子，定义了一个Zuul过滤器，实现了在请求被路由之前检查请求中是否有accessToken参数，若有就进行路由，若没有就拒绝访问，返回401 Unauthorized错误。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ZuulPreFilter extends ZuulFilter &#123; private static Logger log = LoggerFactory.getLogger(ZuulPreFilter.class); /** * ZuulFilter 的类型 * @return */ @Override public String filterType() &#123; return \"pre\"; &#125; /** * 执行顺序控制 * @return */ @Override public int filterOrder() &#123; return 0; &#125; /** * 返回一个boolean类型来判断该过滤器是否要执行，所以通过此函数可实现过滤器的开关。我们直接返回true，所以该过滤器总是生效。 * @return */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * 过滤器的具体逻辑。这里我们通过ctx.setSendZuulResponse(false)令zuul过滤该请求，不对其进行路由， * 然后通过ctx.setResponseStatusCode(401)设置了其返回的错误码， * 当然我们也可以进一步优化我们的返回，比如，通过ctx.setResponseBody(body)对返回body内容进行编辑等。 */ @Override public Object run() throws ZuulException &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); log.info(String.format(\"%s request to %s\", request.getMethod(), request.getRequestURL().toString())); Object accessToken = request.getParameter(\"accessToken\"); if(accessToken == null) &#123; log.warn(\"access token is empty\"); ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(401); ctx.setResponseBody(\"access token is empty\"); return null; &#125; log.info(\"access token ok\"); return null; &#125;&#125; 实现了自定义过滤器之后，向容器中注入ZuulPreFilter 123456789101112131415161718192021222324252627@EnableZuulProxy@EnableEurekaClient@SpringCloudApplicationpublic class WebGatewayApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate() &#123; SimpleClientHttpRequestFactory simpleClientHttpRequestFactory = new SimpleClientHttpRequestFactory(); simpleClientHttpRequestFactory.setConnectTimeout(10000); simpleClientHttpRequestFactory.setReadTimeout(10000); return new RestTemplate(simpleClientHttpRequestFactory); &#125; /** * 加入ZuulPreFilter */ @Bean public ZuulPreFilter zuulPreFilter() &#123; return new ZuulPreFilter(); &#125; public static void main(String[] args) &#123; SpringApplication.run(WebGatewayApplication.class, args); &#125;&#125; 重新启动我们的Web Gateway服务，访问http://localhost:9400/pay/api/pay/testPay：状态码401，响应体access token is empty访问http://localhost:9400/pay/api/pay/testPay?accessToken=xxx：状态码200，响应体test，访问成功对于其他一些过滤类型，这里就不一一展开了，根据之前对filterType生命周期介绍，可以参考下图去理解，并根据自己的需要在不同的生命周期中去实现不同类型的过滤器。最后，总结一下为什么服务网关是微服务架构的重要部分，是我们必须要去做的原因： 不仅仅实现了路由功能来屏蔽诸多服务细节，更实现了服务级别、均衡负载的路由。 实现了接口权限校验与微服务业务逻辑的解耦。通过服务网关中的过滤器，在各生命周期中去校验请求的内容，将原本在对外服务层做的校验前移，保证了微服务的无状态性，同时降低了微服务的测试难度，让服务本身更集中关注业务逻辑的处理。 实现了断路器，不会因为具体微服务的故障而导致服务网关的阻塞，依然可以对外服务。","tags":[{"name":"API GateWay","slug":"API-GateWay","permalink":"http://blog.pcluo.com/tags/API-GateWay/"}]},{"title":"Spring-Cloud微服务架构（三）断路器","date":"2018-05-09T08:51:51.000Z","path":"2018/05/09/Spring-Cloud微服务架构（三）断路器/","text":"在微服务架构中，我们把整个系统拆分成一个个的子服务，每个服务之间通过注册与订阅的方式进行相互依赖。每个服务在不同的进程中运行，通过远程调用的方式进行访问。这样就有可能因为网络原因或是依赖服务自身问题出现调用故障或延迟，而这些问题会直接导致调用方的对外服务也出现延迟，若此时调用方的请求不断增加，最后就会出现因等待出现故障的依赖方响应而形成任务积压，最终导致自身服务的瘫痪。形成服务器雪崩 如上图所示：A为服务提供者，B为A的服务调用者，C和D是B的服务调用者。当A的不可用，引起B的不可用，并将不可用逐渐放大C和D时，服务雪崩就形成了。 Netflix Hystrix断路器在Spring Cloud中使用了Hystrix 来实现断路器的功能。Hystrix是Netflix开源的微服务框架套件之一，该框架目标在于通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能。 继续之前的的两个服务来做断路器测试。 启动Eureka Server、Pay Server、Provider Server访问http://localhost:9200/api/pay/testProviderRibbon，调用Provider Server的服务，可以看到我们的测试返回 testProvider success。 然后我们关闭 Provider Server，在浏览器再次访问http://localhost:9200/api/pay/testProviderRibbon，我们得到报错信息。 1234567Whitelabel Error PageThis application has no explicit mapping for /error, so you are seeing this as a fallback.Wed May 09 23:06:29 CST 2018There was an unexpected error (type=Internal Server Error, status=500).I/O error on POST request for &quot;http://provider-server/api/provider/testProvider&quot;: Connection refused: connect; nested exception is java.net.ConnectException: Connection refused: connect 开启Pay Server服务的断路器功能，在住应用类PayServerApplication.java上加上@EnableCircuitBreaker，代码如下： 123456789101112131415@EnableEurekaClient@SpringCloudApplication@EnableFeignClients //Feign支持public class PayServerApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(PayServerApplication.class, args); &#125;&#125; 可以看到我们，没有加上这个注解。因为我们用的是@SpringCloudApplication这个注解，它里面包含了@EnableCircuitBreaker这个注解 123456789@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootApplication@EnableDiscoveryClient@EnableCircuitBreakerpublic @interface SpringCloudApplication &#123;&#125; Ribbon中使用Hystrix改造Pay Server 的TestPayController.java 类，在接口testProviderRibbon加入注解@HystrixCommand，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@RestController@RequestMapping(\"/api/pay\")public class TestPayController &#123; private final static Logger log = LoggerFactory.getLogger(TestPayController.class); @Autowired private DiscoveryClient client; @Autowired private ProviderFeginCustomClient feignClient; @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; @RequestMapping(\"/testPay\") public String testPay()&#123; List&lt;ServiceInstance&gt; instances = client.getInstances(\"pay-server\"); ServiceInstance instance = instances.get(0); log.info(\"/testPay, host:\" + instance.getHost() + \", service_id:\" + instance.getServiceId()); return \"test\"; &#125; @RequestMapping(\"/testProviderFeign\") public String testProviderFeign()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"testProviderFeign &gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return feignClient.testProvider(); &#125; @RequestMapping(\"/testProviderRibbon\") @HystrixCommand(fallbackMethod = \"testProviderRibbonFallback\") public String testProviderRibbon()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); &#125; private String testProviderRibbonFallback()&#123; return \"error\"; &#125;&#125; 可以看到我们现在已经在 testProviderRibbon方法上加上了注解，并且添加了一个回调方法。 现在，我们重新启动Pay Server，也就是我们只启动Eureka Server和Pay Server两个服务，再次访问http://localhost:9200/api/pay/testProviderRibbon，我们可以看到页面显示：error Feign中使用Hystrix1、Feign 是默认关闭 Hystrix的，所以我们要在配置里打开它，修改Pay Server的application.yml 1234567891011121314151617181920212223242526272829303132333435---server: port: 9200eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: pay-server profiles: peer1provider-server: ribbon:# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮调 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRulefeign: hystrix: enabled: true##断路器 将 hystrix 的超时时间设置成 60000 毫秒（60秒）hystrix: command: default: execution: timeout: enabled: false isolation: thread: timeoutInMilliseconds: 60000 也就是添加了feign.hystrix.enabled=true 这个属性。 2、创建类ProviderFeginCustomClientFallback.java，并且实现ProviderFeginCustomClient.java 12345678@Componentpublic class ProviderFeginCustomClientFallback implements ProviderFeginCustomClient &#123; @Override public String testProvider() &#123; return \"errorFeign\"; &#125;&#125; 3、修改ProviderFeginCustomClient.java，在@FeignClient中添加属性 fallback，并配置为ProviderFeginCustomClientFallback。 12345678@FeignClient(name = \"provider-server\", fallback = ProviderFeginCustomClientFallback.class)public interface ProviderFeginCustomClient &#123; @RequestMapping(value = \"/api/provider/testProvider\", method = RequestMethod.GET) public String testProvider();&#125; 现在，我们重新启动Pay Server，也就是我们只启动Eureka Server和Pay Server两个服务，在浏览器访问http://localhost:9200/api/pay/testProviderFeign，我们可以看到页面显示：errorFeign","tags":[{"name":"Hystrix","slug":"Hystrix","permalink":"http://blog.pcluo.com/tags/Hystrix/"}]},{"title":"Spring Cloud微服务架构（二）服务消费者","date":"2018-05-07T11:36:11.000Z","path":"2018/05/07/Spring-Cloud微服务架构（二）服务消费者/","text":"在上一篇中《Spring Cloud微服务架构（一）高可用服务注册与发现》中，我们已经创建了服务注册中心，并且注册了一个服务提供者 pay-server，那么接下来我们要怎么去消费提供者提供的接口呢？ 首先创建 Provider Server 服务提供方创建一个基本的Provider Server 项目，在pom.xml 引入以下依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.blog&lt;/groupId&gt; &lt;artifactId&gt;provider-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;provider-server&lt;/name&gt; &lt;description&gt;provider-server&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RC1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 创建好Provider Server 项目后，主应用类将@SpringBootApplication修改为SpringCloudApplication注解，将此服务注册到Eureka Server中，代码如下： 12345678@EnableEurekaClient@SpringCloudApplicationpublic class ProviderServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderServerApplication.class, args); &#125;&#125; 配置application.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344---server: port: 9300eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: provider-server profiles: peer1---server: port: 9301eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: provider-server profiles: peer2---server: port: 9302eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: provider-server profiles: peer3 这里有三个配置，用来测试我们的负载均衡，服务调用方具体是访问的是那个端口下的服务。 接下来编写一个提供其他服务调用的接口，这里也就是我们的Pay Server来调用，代码如下： 1234567891011121314151617@RestController@RequestMapping(\"/api/provider\")public class TestProviderController &#123; private final static Logger log = LoggerFactory.getLogger(TestProviderController.class); @Autowired private LoadBalancerClient loadBalancerClient; @RequestMapping(\"testProvider\") public String testProvider()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return \"testProvider success\"; &#125;&#125; 到此，服务提供方就已经做好了。 RibbonRibbon 是一个客户端负载均衡器，可以让您对HTTP和TCP客户端的行为有很多控制权。Feign已经使用Ribbon，因此，如果您使用@FeignClient，此部分也适用。原理我们这里就不做过多说明，直接进入实战演练。 下面我们通过实例看看如何使用Ribbon来调用服务，并实现客户端的均衡负载。 上面，我们已经创建好了Provider Server服务提供方，在Pay Server中使用Ribbon来进行消费。 1、在pom.xml 中引入新的依赖12345678910&lt;!-- 服务消费者 ribbon openfeign 这里直接把两个依赖都加上 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 2、修改Pay Server主应用类：1234567891011121314@EnableEurekaClient@SpringCloudApplicationpublic class PayServerApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(PayServerApplication.class, args); &#125;&#125; 3、创建TestPayController.java 来消费Provider Server的 testProvider 服务，通过直接RestTemplate来调用服务。1234567891011121314151617181920212223@RestController@RequestMapping(\"/api/pay\")public class TestPayController &#123; private final static Logger log = LoggerFactory.getLogger(TestPayController.class); @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; /** * Ribbon方式访问 */ @RequestMapping(\"/testProviderRibbon\") public String testProviderRibbon()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); &#125;&#125; 4、修改application.yml123456789101112131415161718192021222324252627282930---server: port: 9200eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: pay-server profiles: peer1provider-server: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮询# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule #加权响应时间# 断路器 将 hystrix 的超时时间设置成 60000 毫秒（60秒）# 解决第一次请求报超时异常的方案，因为 hystrix 的默认超时时间是 1 秒，因此请求超过该时间后，就会出现页面超时显示 ：hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 60000 以上工作做完之后，我们就可以启动Pay Server和Provider Server了。将Provider Server分别根据配置启动三次（Spring Cloud微服务架构（一）高可用服务注册与发现 有说明如何根据不同配置启动）。启动后如下图接下来我们访问http://localhost:9200/api/pay/testProviderRibbon（也就是我们Pay Server的接口），查看日志和访问结果。调用日志：访问结果：我们可以看到，按顺序访问的端口服务器，这是因为我们在配置负载均衡的时候使用的是轮询模式。修改负载均衡模式（这次我们使用随机分配模式），我们在次调用。调用日志： 可以发现，现在调用的端口服务器是随机的。这里，通过Ribbon的方式来消费服务的方式就已经做好了。 Feign之前我们做Ribbon的时候，已经做了很多的准备工作，并且已经在pom.xml 文件中新添加了Feign 的依赖，所以这里我们直接开始。 1、添加访问远端服务 Feign 客户端ProviderFeginCustomClient.java，代码如下：1234567@FeignClient(name = \"provider-server\")public interface ProviderFeginCustomClient &#123; @RequestMapping(value = \"/api/provider/testProvider\", method = RequestMethod.GET) public String testProvider();&#125; 2、在TestProviderController.java中添加 Feign 方式访问的接口，代码如下：123456789101112131415161718192021222324252627282930313233343536@RestController@RequestMapping(\"/api/pay\")public class TestPayController &#123; private final static Logger log = LoggerFactory.getLogger(TestPayController.class); @Autowired private ProviderFeginCustomClient feignClient; @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; /** * Feign方式访问 */ @RequestMapping(\"/testProviderFeign\") public String testProviderFeign()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"testProviderFeign &gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return feignClient.testProvider(); &#125; /** * Ribbon方式访问 */ @RequestMapping(\"/testProviderRibbon\") public String testProviderRibbon()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); &#125;&#125; 重新启动Pay Server服务，访问http://localhost:9200/api/pay/testProviderFeign。调用日志：访问结果：根据日志和访问结果，我们的Feign 是配置成功了。这里的端口很明显是随机的，应为我们在做Ribbon的时候将它设置成了随机的负载均衡调度。到此Ribbon和Feign的服务消费就结束了。 那么，我们在开发的时候会想，到底使用Ribbon呢，还是Feign呢？ 现在我们就来分析一波，从代码上来看，我们使用Ribbon很方便快捷，只要在服务主应用类上加入下面一段代码。12345@Bean@LoadBalanced //开启负载均衡RestTemplate restTemplate()&#123; return new RestTemplate();&#125; 然后使用的时候，只要在其中注入 RestTemplate即可使用，通过调用RestTemplate的接口即可，例如下面的代码片 1return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); 反观Feign，需要创建一个 Feign 客户端甚至是Feign 的配置（此案例中还未涉及Feign 的配置），显得旧没有那么方便快捷了。我们可以看到上面的 Feign 客户端ProviderFeginCustomClient.java，在调用的时候，注入Feign 客户端，直接调用接口即可，如下面的代码片段。 1return feignClient.testProvider(); 我们发现 Feign的调用方式就很像调用本地的方法，甚至感觉不到我们是在跨服务调用。 这里笔者的想法是这样的，在我们实际的项目中，如果我在消费者服务（这里也就是Pay Server）在不用过多的去调用提供方（这里也就是Provider Server）的接口时，我们倾向于使用Ribbon，因为它够方便，够简单。反之，我们倾向于使用Feign来做服务消费。我们可以看到Feign更具有封装性，将我们所有的服务调用，全部可以封装在 FeignClient 中，维护起来也方便。 我们可以一开始的时候使用Ribbon来做服务间的调用，之后变多的情况下，考虑代码重构。","tags":[{"name":"Ribbon","slug":"Ribbon","permalink":"http://blog.pcluo.com/tags/Ribbon/"},{"name":"Feign","slug":"Feign","permalink":"http://blog.pcluo.com/tags/Feign/"}]},{"title":"Spring Cloud微服务架构（一）高可用服务注册与发现","date":"2018-05-07T09:02:25.000Z","path":"2018/05/07/Spring-Cloud微服务架构（一）高可用服务注册与发现/","text":"创建“服务注册中心”创建一个基础的Spring Boot EurekaServer项目，在pom.xml 中引入需要的依赖​ 注意：在创建Spring Boot 项目时，版本的选择。本次系列文章均采用最新版本的2.0.1版本对应关系​ 为什么要在这里说明一下，因为不同的版本，你写的pom依赖可能不同。如下面的 服务注册依赖，​ 在Spring Boot 1.5.x 版本中 spring-cloud-starter-eureka-server 是这个，如何去找准确的依赖，要去​ 看官方文档，去里面找。如Spring Boot 2.0.1 Eureka Server 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.geeur.demo.cloud&lt;/groupId&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;description&gt;eureka-server&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.M9&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 服务注册 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 创建好EurekaServer 项目后，通过@EnableEurekaServer注解启动一个服务注册中心提供给其他应用进行对话。这一步只需要在你的Spring Boot 应用中添加这个注解，就可以开启此功能。代码如下： 12345678@EnableEurekaServer@SpringCloudApplicationpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 这里使用更改了创建项目时的@SpringBootApplication注解，变为@SpringCloudApplication，其实就是一个注解的整合，这里不做过多说明。 注意：使用@SpringCloudApplication时，需要加入断路器的依赖。使用@SpringBootApplication则可以不加断路器依赖，原因是@SpringCloudApplication注解里面包含@EnableCircuitBreaker这个注解，它需要断路器的自动配置。接下来就是application.yml 的配置(默认创建项目时生成的是application.properties 文件) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108# 测试环境 peer1---# 服务端口server: port: 9100eureka: server: # 正式环境不推荐加入此配置，以下server 配置为 Eureka Server的自我保护机制，在我们测试时候加入，是为了看效果 eviction-interval-timer-in-ms: 5000 enable-self-preservation: false client: # 是否向服务注册中心注册自己 register-with-eureka: true # 是否检索服务 fetch-registry: true serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: peer1 appname: $&#123;spring.application.name&#125; # 以下两个配置正式环境推荐使用默认值，不建议修改 # 表示eureka client间隔多久去拉取服务注册信息，默认为30秒，对于api-gateway，如果要迅速获取服务注册状态，可以缩小该值，比如5秒 lease-renewal-interval-in-seconds: 5 # 表示eureka server至上一次收到client的心跳之后，等待下一次心跳的超时时间，在这个时间内若没收到下一次心跳，则将移除该instance lease-expiration-duration-in-seconds: 10spring: application: # 微服务名称，后续在调用的时候只需要使用该名称就可以进行服务的访问 name: eureka-server profiles: peer1# 测试环境 peer2---server: port: 9101eureka: server: eviction-interval-timer-in-ms: 5000 enable-self-preservation: false client: register-with-eureka: true fetch-registry: true serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: peer2 appname: $&#123;spring.application.name&#125; lease-renewal-interval-in-seconds: 5 lease-expiration-duration-in-seconds: 10spring: application: name: eureka-server profiles: peer2# 测试环境 peer3---server: port: 9102eureka: server: eviction-interval-timer-in-ms: 5000 enable-self-preservation: false client: register-with-eureka: true fetch-registry: true serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: peer3 appname: $&#123;spring.application.name&#125; lease-renewal-interval-in-seconds: 5 lease-expiration-duration-in-seconds: 10spring: application: name: eureka-server profiles: peer3#生产环境推荐配置---server: port: 9103eureka: client: serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/,http://prod:9103/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: prod appname: $&#123;spring.application.name&#125;spring: application: name: eureka-server profiles: prod 注意：这里需要在你们的 hosts 文件中加入如下配置 123127.0.0.1 peer1127.0.0.1 peer2127.0.0.1 peer3 因为我们要做Eureka Server 的集群，所以这个在我的application.yml 配置中，分别有三个配置peer1、peer2、peer3。然后我们启动Eureka Server 三次，根据不同的配置，在IDEA 中如何启动这三个配置。 修改Program arguments: –spring.profiles.active=peer1、 –spring.profiles.active=peer2、–spring.profiles.active=peer3，启动三次即可。任意访问其中一个： 可以看到我们的集群已经搭建好了。这里我们为什么要注册自己（register-with-eureka: true和fetch-registry: true这两个配置），我们可以看到下面那个红框中的数据，registered-replicas（注册副本）、unavailable-replicas（不可用副本）、available-replicas（可用副本）。当我们其中某一个Eureka Server 死掉的时候，unavailable-replicas就会有死掉的是哪一个Eureka Server，根据这个，我们就可以快速的重启对应的Eureka Server。 通常情况下是，启动两个注册中心c1和c2，但是在c1注册中心的available-replicas项中没有c2存在，反而是unavailable-replicas中有。 加入的配置为： 12345# 1、默认即可，源码中，这两个配置均为 trueregister-with-eureka: truefetch-registry: true# 2、eureka.client.serviceUrl.defaultZone配置项的地址，不能使用localhost，要使用service-center-1之类的域名，通过host映射到127.0.0.1；这里使用的是peer1、peer2、peer3# 3、spring.application.name或eureka.instance.appname必须一致； 现在我们将peer2 的Eureka Server 死掉，再看情况 我们可以看到 http://peer2:9101/eureka/ 出现在 unavailable-replicas，在我们的注册区EUREKA-SERVER 中也只有两个Eureka Server。 创建“服务提供方”创建提供支付服务的为服务模块，并向服务注册中心注册 创建一个名叫Pay Server 的Spring Boot 服务模块，在pom.xml 引入如下配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.geeur&lt;/groupId&gt; &lt;artifactId&gt;pay-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;pay-server&lt;/name&gt; &lt;description&gt;pay-server&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.M9&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;weixin-server&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 然后在主应用类上加上@EnableDiscoveryClient注解，该注解能激活Eureka中的DiscoveryClient实现，才能实现Controller中对服务信息的输出。 1234567891011/** * 把 @SpringBootApplication 修改为 @SpringCloudApplication * 此注解中已经包含了 @EnableDiscoveryClient 注解 */@SpringCloudApplicationpublic class PayServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(PayServerApplication.class, args); &#125;&#125; 接下来就是application.yml 的配置(默认创建项目时生成的是application.properties 文件) 1234567891011121314server: port: 9200eureka: client: service-url: # 指定服务注册中心的位置（这里指定集群中的一个就可以） defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: # 微服务名称，后续在调用的时候只需要使用该名称就可以进行服务的访问 name: pay-server 启动Pay Server 项目，访问我们的http://peer1:9100，显示如下图： 我们可以看到我们的服务中心已经注册了Pay Server，现在我们将 peer1的Eureka Server杀掉，为什么杀掉它，因为我们的Pay Server 中，defaultZone是向http://peer1:9100/eureka/注册的。显示如下图： 可以看到，我们的unavailable-replicas 中出现了http://peer1:9100/eureka/，但是我们的注册区任然是存在Pay Server 这个服务的。","tags":[{"name":"Eureka","slug":"Eureka","permalink":"http://blog.pcluo.com/tags/Eureka/"}]},{"title":"HashMap和HashSet实现原理","date":"2018-05-03T08:50:57.000Z","path":"2018/05/03/HashMap和HashSet实现原理/","text":"HashMap分析前言HashMap的数据结构：HashMap的数据结构是：数组 + 单向链表 的形式。 1、我们先从new HashMap();这里开始分析HashMap。进入源码分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; /** * The default initial capacity - MUST be a power of two. * 初始化时默认的HashMap容量, 必须为2的次幂值。 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. * 默认的HashMap最大的容量, 用以限制参数及表格最大容量, 必须是&lt;= 1&lt;&lt;30的2的次幂。 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * The load factor used when none specified in constructor. * 默认加载因子, 在构造的时候没有给定的情况下 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. * 由链表转换成树的阈值TREEIFY_THRESHOLD（链表转树） * 一个桶中bin（箱子）的存储方式由链表转换成树的阈值。即当桶中bin的数量超过TREEIFY_THRESHOLD时使用树来代替链表。默认值是8 */ static final int TREEIFY_THRESHOLD = 8; /** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. * 由树转换成链表的阈值UNTREEIFY_THRESHOLD（树转链表） * 当执行resize操作时，当桶中bin的数量少于UNTREEIFY_THRESHOLD时使用链表来代替树。默认值是6 */ static final int UNTREEIFY_THRESHOLD = 6; /** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. * 当桶中的bin被树化时最小的hash表容量。（如果没有达到这个阈值，即hash表容量小于MIN_TREEIFY_CAPACITY，当桶中bin的数量太多时会执行resize扩容操作）这个MIN_TREEIFY_CAPACITY的值至少是TREEIFY_THRESHOLD的4倍。 */ static final int MIN_TREEIFY_CAPACITY = 64; /** * The next size value at which to resize (capacity * load factor). * 表示当HashMap的size大于threshold时会执行resize操作 * @serial */ int threshold; /** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) * HashMap 存放的Node&lt;K,V&gt;[] */ transient Node&lt;K,V&gt;[] table;&#125; 这里我们来看一下 HashMap的四个构造方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity 初始容量值 * @param loadFactor the load factor 加载因子值 * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */public HashMap(int initialCapacity, float loadFactor) &#123; //如果传入的容量大小小于0，抛出IllegalArgumentException 异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); //如果传入的容量大小大于最大的容量，则修改成最大的容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //加载因子，小于0 或者 不是Float，抛出IllegalArgumentException 异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. 初始容量值 * @throws IllegalArgumentException if the initial capacity is negative. */public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;/** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 我们重点关注前面三个，通常我们直接用的是new HashMap();这一个构造器。可以看到这个构造器只有初始化loadFactor（加载因子） 这个变量。在来看 HashMap(int initialCapacity)，此构造函数调用HashMap(int initialCapacity, float loadFactor)这一个构造函数，我们来看一下这个构造函数的最后一行代码，看下他的实现this.threshold = tableSizeFor(initialCapacity);，这里也就是设置HashMap扩容的闸阀。当后续操作不断的增加HashMap的容量时，超过this.threshold值时，HashMap进行扩容。 12345678910111213/** * Returns a power of two size for the given target capacity. * 输出不小于cap的第一个2的n次幂，作为threshold，比如cap = 3，就变成了4 */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 2、HashMap存放值我们再来看HashMap.put()方法，跟着里面的注释进行分析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V put(K key, V value) &#123; //hash(key) 做hash处理，得到key对应的hash值 return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //这里table 通常情况下第一次put值时为null，除非在创建HashMap 的时候使用的是 HashMap(Map&lt;? extends K, ? extends V&gt; m)这一个构造器。 if ((tab = table) == null || (n = tab.length) == 0) //初始化table 或者给table 扩容 n = (tab = resize()).length; //i = (n - 1) &amp; hash：根据数组的大小，以及key 的hash 值，确定放入在tab数组中的位置。 //判断tab数组中，该位置是否为空。 //(n - 1) &amp; hash 决定当前的key 在tab 中的位置，这里也是为什么我们的容量必须是2的幂 (n - 1) &amp; hash 相当于 hash % (n-1) ，得到的值必定在 0 - (n-1) 之间，n又等于tab[] 的size，(n - 1) &amp; hash运算效率又极其之高。 if ((p = tab[i = (n - 1) &amp; hash]) == null) //为空，创建一个新的Node&lt;key, value&gt;，并赋值给tab[i] tab[i] = newNode(hash, key, value, null); else &#123; //不为空处理 Node&lt;K,V&gt; e; K k; //判断tab[i] 中 key 是否与put 进来的key 相同，这里使用hash和equals来进行比对 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //相同的情况下将p(tab[i]) 赋值给 e 即 tab[i]-&gt;p e-&gt;p e = p; else if (p instanceof TreeNode) //tab[i] 中 key 是与put 进来的key 不相同，且此时我们的Node 链表转化为 TreeNode链表了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //tab[i] 中 key 是与put 进来的key 不相同 for (int binCount = 0; ; ++binCount) &#123; //将p(tab[i])的下一个节点Node 赋值给e，判断e是不是为null if ((e = p.next) == null) &#123; //e == null 创建Node，将p(tab[i])指向新的Node（put 进来的key、value），并且结束循环 p.next = newNode(hash, key, value, null); //如果此时新加入的元素，造成了链表过大，将链表Node 转化为 TreeNode if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //判断e(p.next)的 key 是与put 进来的key 相同，相同则结束循环，不同将p -&gt; e，再次循环判断 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // p -&gt; e p = e; &#125; &#125; //判断e != null，即此时put 的值，在原来的tab 中已经存在，这里也就是将新的value 替换原有的value。 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) //tab 扩容 resize(); afterNodeInsertion(evict); return null;&#125;/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //将旧表中的数据复制给新表中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 可以看到，这里的分析的很多，那我们中点来看这一段代码： 12345678910111213141516171819202122232425262728293031323334353637//不为空处理Node&lt;K,V&gt; e; K k;//判断tab[i] 中 key 是否与put 进来的key 相同，这里使用hash和equals来进行比对if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //相同的情况下将p(tab[i]) 赋值给 e 即 tab[i]-&gt;p e-&gt;p e = p;else if (p instanceof TreeNode) //tab[i] 中 key 是与put 进来的key 不相同，且此时我们的Node 链表转化为 TreeNode链表了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);else &#123; //tab[i] 中 key 是与put 进来的key 不相同 for (int binCount = 0; ; ++binCount) &#123; //将p(tab[i])的下一个节点Node 赋值给e，判断e是不是为null if ((e = p.next) == null) &#123; //e == null 创建Node，将p.next(tab[i].next)指向新的Node（put 进来的key、value），并且结束循环，这里其实就是把p.next(tab[i].next)指向新的Node p.next = newNode(hash, key, value, null); //如果此时新加入的元素，造成了链表过大，将链表Node 转化为 TreeNode if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //判断e(p.next)的 key 是与put 进来的key 相同，相同则结束循环，不同将p -&gt; e，再次循环判断 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // p -&gt; e p = e; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; p -&gt; tab[i]，我们put 一个值到tab[i] 位置上，此时tab[i] 已经存在值。 当我们put 一个值时，首先会判断 put 的 key 是否与tab[i] 中的key 相同。相同 e -&gt; p，跳出if else，向下执行。不相同，判断当前的p 是否为 TreeNode类型，不为TreeNode 类型，执行else，进入for循环。重点来了。 if ((e = p.next) == null)首先将p.next赋给e并判断是否为null，如果为空（此时tab[i]中，有且仅有一个Node），创建一个新的Node 赋值给p.next，在判断此时 tab[i]链表中的Node 数量是否超过闸阀 TREEIFY_THRESHOLD，超过则把Node类型 转换为 TreeNode类型。跳出循环。（因为e = p.next为null，所以if (e != null)下面不再执行） if ((e = p.next) == null)首先将p.next赋给e并判断是否为null，如果不为空（此时tab[i]中，存在2个以上Node或TreeNode），我们看if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))，因为我们之前只检验了我们put 进来的值 与tab[i] 上的这个值是否相同，那后面的链表中，所有的值都要进行检验是否相同。如果相同，直接跳出循环，进入if (e != null)继续执行。将新put 进来的 value 替换 oldValue。如果校验不相同，则p = e，继续进行循环，如果所有的Node 的key 与新put 的key 都不同的话，则把新put 的值放在链表结尾。 当put 完之后，进行判断if (++size &gt; threshold)，是否需要对HashMap 进行扩容。 3、HashMap取值我们再来看HashMap.get()方法，跟着里面的注释进行分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Returns the value to which the specified key is mapped, * or &#123;@code null&#125; if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code (key==null ? k==null : * key.equals(k))&#125;, then this method returns &#123;@code v&#125;; otherwise * it returns &#123;@code null&#125;. (There can be at most one such mapping.) * * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to &#123;@code null&#125;. * The &#123;@link #containsKey containsKey&#125; operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //判断 table 是否为 null，或者table.length 是不是大于0，并且tab[(n - 1) &amp; hash] 对应的值不能为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //判断第一个 Node(first) 的 key 是否与 传入的 key 相同，相同直接返回 first if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //判断下一个Node 是否为 null if ((e = first.next) != null) &#123; //判断是否为TreeNode 类型 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //执行循环 判断当前的Node(e) 的 key 是否与 传入的 key 相同，相同直接返回 e，不相同，判断(e = e.next) != null。继续执行，如果最后没有找到，直接返回null if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 这里我们看以看到HashMap.get()的思路跟HashMap.put()的思路是一样的。都是通过比较 key 的 hash值 和 equals 来看 可以是否 key 相同。首先找到key 的hash 在table[] 中的位置，匹对table[i] 的key 是否与 get 的 key相同，不相同，寻找table[i] 的下一个节点Node，对整个链表进行遍历。找到则取出，没有找到继续遍历，直到整个链表遍历完成，若遍历完成之后还未找到，则返回null。 4、HashMap的工作原理HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到table位置来储存Entry对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//put 中加入新Node newNode(hash, key, value, null);Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next);&#125;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 5、HashMap注意事项 减少”碰撞”发生，经过我们的源码分析。一旦发生key的 hash值碰撞，就会在”碰撞”位置开始对整个链表遍历，链表的遍历会带来效率的影响。通常我们使用String，Interger这样的wrapper类作为HashMap 的key。或者使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法，来减少碰撞的发生。 避免扩容，在resize()方法中，我们可以看下是怎么扩容的。关键代码： 1234567891011if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //通常执行这里，newCap = oldCap &lt;&lt; 1 也就是扩大一倍原来的容量 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold&#125;Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; 这个开销是非常大的，在table[] 数组中扩容。扩容之后，还要把oldTab 中的数据复制到 newTab中。在我们使用HashMap 的时候尽可能的估算map 的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容 。 不能在多线程中使用HashMap，HashMap是非线程安全的。在扩容的时候，HashMap可能造成死循环。 负载因子可以进行修改，但不建议去修改，因为这个是经过科学计算得出的一个值，除非特殊情况下。 HashSet分析上面我们分析了HashMap，为什么我们先分析HashMap 呢？直接进入主题，这里我们列出部分代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; private transient HashMap&lt;E,Object&gt; map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * default initial capacity (16) and load factor (0.75). */ public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; /** * Constructs a new set containing the elements in the specified * collection. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with default load factor * (0.75) and an initial capacity sufficient to contain the elements in * the specified collection. * * @param c the collection whose elements are to be placed into this set * @throws NullPointerException if the specified collection is null */ public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125; /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and the specified load factor. * * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */ public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor); &#125; /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and default load factor (0.75). * * @param initialCapacity the initial capacity of the hash table * @throws IllegalArgumentException if the initial capacity is less * than zero */ public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity); &#125; /** * Constructs a new, empty linked hash set. (This package private * constructor is only used by LinkedHashSet.) The backing * HashMap instance is a LinkedHashMap with the specified initial * capacity and the specified load factor. * * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @param dummy ignored (distinguishes this * constructor from other int, float constructor.) * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */ HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125;&#125; 可以看到，我们的HashSet在构造的时候，都会实例一个HashMap。 再来看HashSet.add方法： 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 可以看到实际上是map.put(e, PRESENT)，用的是HashMap 的put 方法。对象作为key，new Object()作为值存放到map 中。 由此可知，HashSet 的原理跟HashMap 的原理是差不多的。 HashSet 取值： 123456789101112/** * 返回对此set中元素进行迭代的迭代器。返回元素的顺序并不是特定的。 * * 底层实际调用底层HashMap的keySet来返回所有的key。 * 可见HashSet中的元素，只是存放在了底层HashMap的key上， * value使用一个static final的Object对象标识。 * @return 对此set中元素进行迭代的Iterator。 */ public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125;//通过迭代器遍历获取值 HsahSet是基于HashMap 实现的，默认构造函数是构建一个初始容量为16，负载因子为0.75 的HashMap。封装了一个 HashMap 对象来存储所有的集合元素，所有放入 HashSet 中的集合元素实际上由 HashMap 的 key 来保存，而 HashMap 的 value 则存储了一个 PRESENT，它是一个静态的 Object 对象。 当我们试图把某个类的对象当成 HashMap的 key，或试图将这个类的对象放入 HashSet 中保存时，重写该类的equals(Object obj)方法和 hashCode() 方法很重要，而且这两个方法的返回值必须保持一致：当该类的两个的 hashCode() 返回值相同时，它们通过 equals() 方法比较也应该返回 true。通常来说，所有参与计算 hashCode() 返回值的关键属性，都应该用于作为 equals() 比较的标准。","tags":[{"name":"HashMap HashSet","slug":"HashMap-HashSet","permalink":"http://blog.pcluo.com/tags/HashMap-HashSet/"}]},{"title":"Servlet 生命周期","date":"2018-05-03T06:00:33.000Z","path":"2018/05/03/Servlet 生命周期/","text":"一个Servlrt 的生命周期可以被定义为从创建到销毁的整个过程。以下是Servlrt 所遵循的路径，我们先看下Servlet 有哪些方法，中点关注那些方法（init()、service()、destroy()） Servlrt 的生命周期分为三个阶段： 1、初始化阶段1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465类加载器加载Servlet --&gt; 容器创建Servlet --&gt; 容器调用Servlet.init()Servlet.init()只会被调用一次，它只在Servlet 创建的时候调用，之后的任何用户请求都不会在被调用。这里在Servlet 创建并初始化的时候，tomcat 会把它放到容器的缓存中来进行管理，在下一次访问的时候看缓存中是否有这个Servlet，如果有则直接拿出来调用。默认情况下Servlet 是什么时候被创建的呢? 我们在web.xml 里面配置我们的Servlet 代码如下 &lt;servlet&gt; &lt;!-- servlet的内部名称，自定义。尽量有意义 --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的类全名： 包名+简单类名 --&gt; &lt;servlet-class&gt;com.blog.demo.servlet.DefaultServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;!-- servlet的映射配置 --&gt; &lt;servlet-mapping&gt; &lt;!-- servlet的内部名称，一定要和上面的内部名称保持一致！！ --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的映射路径（访问servlet的名称） --&gt; &lt;url-pattern&gt;/servlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; Servlet public class DefaultServlet extends HttpServlet &#123; public DefaultServlet() &#123; System.out.println(\"DefaultServlet construct\"); &#125; @Override public void init() throws ServletException &#123; System.out.println(\"DefaultServlet init\"); super.init(); &#125; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(\"DefaultServlet doGet\"); super.doGet(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(\"DefaultServlet doPost\"); super.doPost(req, resp); &#125; @Override public void destroy() &#123; System.out.println(\"DefaultServlet destroy\"); super.destroy(); &#125;&#125;此时我们启动我们的容器，这里以tomcat容器为例，启动我们的tomcat 查看启动日志，我们并没有发现控制台有打印 DefaultServlet init，这是我们访问一下我们的Servlet doGet方法我们看打印的日志DefaultServlet constructDefaultServlet initDefaultServlet doGet即Servlet 在我们访问的时候被创建，并且初始化，之后再次调用不再调用Servlet.init()方法。第一次调用Servlet.doGet()的方法时，tomcat 会判断容器中是否有这个Servlet 的实例，如果有则直接调用Servlet.doGet()，如果没有则创建Servlet 并调用 init 方法。之后再次访问就不再调用Servlet.init()日志如下图： 1234567891011121314151617通常我们会在 web.xml Servlet 配置里面加上 &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; 这样一个配置，这个配置的作用就是告诉web容器(tomcat) 在容器启动时就加载这个Servlet，现在我们把这个配置加上，然后再启动web容器，我们发现tomcat 在启动时就帮我们创建了Servlet 并且初始化 &lt;servlet&gt; &lt;!-- servlet的内部名称，自定义。尽量有意义 --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的类全名： 包名+简单类名 --&gt; &lt;servlet-class&gt;com.blog.demo.servlet.DefaultServlet&lt;/servlet-class&gt; &lt;!-- 默认容器启动时创建Servlet --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- servlet的映射配置 --&gt; &lt;servlet-mapping&gt; &lt;!-- servlet的内部名称，一定要和上面的内部名称保持一致！！ --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的映射路径（访问servlet的名称） --&gt; &lt;url-pattern&gt;/servlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 2、相应客户端请求阶段12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Servlet 在创建好之后，就处于响应就绪状态，只要有请求过来就会执行Servlet.service()。为什么我们在上面直接说请求Servlet.doGet()方法呢？以下是HttpServlet 对service 的处理public abstract class HttpServlet extends GenericServlet implements Serializable &#123; public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; HttpServletRequest request; HttpServletResponse response; try &#123; request = (HttpServletRequest)req; response = (HttpServletResponse)res; &#125; catch (ClassCastException var6) &#123; throw new ServletException(\"non-HTTP request or response\"); &#125; this.service(request, response); &#125; protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); long lastModified; if (method.equals(\"GET\")) &#123; lastModified = this.getLastModified(req); if (lastModified == -1L) &#123; this.doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(\"If-Modified-Since\"); if (ifModifiedSince &lt; lastModified / 1000L * 1000L) &#123; this.maybeSetLastModified(resp, lastModified); this.doGet(req, resp); &#125; else &#123; resp.setStatus(304); &#125; &#125; &#125; else if (method.equals(\"HEAD\")) &#123; lastModified = this.getLastModified(req); this.maybeSetLastModified(resp, lastModified); this.doHead(req, resp); &#125; else if (method.equals(\"POST\")) &#123; this.doPost(req, resp); &#125; else if (method.equals(\"PUT\")) &#123; this.doPut(req, resp); &#125; else if (method.equals(\"DELETE\")) &#123; this.doDelete(req, resp); &#125; else if (method.equals(\"OPTIONS\")) &#123; this.doOptions(req, resp); &#125; else if (method.equals(\"TRACE\")) &#123; this.doTrace(req, resp); &#125; else &#123; String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[]&#123;method&#125;; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(501, errMsg); &#125; &#125;&#125;通过HttpServlet 的源码，我们知道在调用service 方法的时候，它会根据请求类型，调用自身的对应的 doGet，doPost，doPut，doDelete ...等方法所以我们在自定义的时候只要Override 这些方法即可。当请求过来的时候，web容器会创建一个新的线程来处理这个请求，web容器来调用对应Servlet.service()，方法Servlet.service()根据请求调用doGet、doPost等方法并完成请求响应，之后线程结束，请求结束。 3、销毁阶段123web容器销毁阶段，会调用应用中所有的Servlet.destroy()。该方法在整个生命周期也是只被调用一次，在Servlet 被销毁的时候，此时我们可以释放掉Servlet 所占用的资源。例如关闭与数据库的连接。下图是容器销毁时调用","tags":[{"name":"源码分析之Servlet","slug":"源码分析之Servlet","permalink":"http://blog.pcluo.com/tags/源码分析之Servlet/"}]},{"title":"博客搭建","date":"2018-03-27T03:15:00.000Z","path":"2018/03/27/博客快速搭建/","text":"快速搭建参看网址搭建 参看网址多机使用 Create a new post and commit1234567cd 你的博客目录$ hexo new \"My New Post\" // /你的博客目录/source/_posts/My New Post.mdgit commit -am 'add My New Post.md and commit'git pushhexo clean // 先进行cleanhexo d -g // 更新到master分支","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://blog.pcluo.com/tags/博客搭建/"}]}]