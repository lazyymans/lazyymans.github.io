[{"title":"聚合支付","date":"2018-05-20T08:01:36.000Z","path":"2018/05/20/聚合支付/","text":"聚合支付目前处于初始阶段，只能使用微信支付(公众号支付、扫码支付、刷卡支付，作者均已测试)。后续跟进开发以及文档的更新… 项目背景作者在经历多次支付业务开发后，同感重复造轮子的痛苦余折磨。也没能在各大网站Github Gitee上找到一款使用的顺手的轮子，于是决定造轮子。 支持支付本项目支持微信、支付宝、paypal、Payoneer等支付。作者将会依次来进行开发。 项目地址聚合支付 文档更新说明API使用","tags":[{"name":"支付","slug":"支付","permalink":"http://blog.pcluo.com/tags/支付/"},{"name":"微信，支付宝","slug":"微信，支付宝","permalink":"http://blog.pcluo.com/tags/微信，支付宝/"}]},{"title":"Mysql 索引","date":"2018-05-20T07:19:45.000Z","path":"2018/05/20/Mysql-索引/","text":"索引的利弊与如何判定，是否需要索引相信读者都知道索引能够极大地提高数据检索的效率，让Query 执行得更快，但是可能并不是每一位朋友都清楚索引在极大提高检索效率的同时，也给数据库带来了一些负面的影响。下面就分别对 MySQL 中索引的利与弊做一个简单的分析。 索引的好处索引带来的益处可能很多读者会认为只是”能够提高数据检索的效率，降低数据库的IO成本”。 确实，在数据库中表的某个字段创建索引，所带来的最大益处就是将该字段作为检索条件时可以极大地提高检索效率，加快检索时间，降低检索过程中须要读 取的数据量。但是索引带来的收益只是提高表数据的检索效率吗？当然不是，索引还有一个非常重要的用途，那就是降低数据的排序成本。我们知 道，每个索引中的数据都是按照索引键键值进行排序后存放的，所以，当Query 语句中包含排序分组操作时，如果排序字段和索引键字段刚好一致，MySQL Query Optimizer 就会告诉 mysqld 在取得数据后不用排序了，因为根据索引取得的数据已经满足客户的排序要求。 那如果是分组操作呢？分组操作没办法直接利用索引完成。但是分组操作是须要先进行排序然后分组的，所以当Query 语句中包含分组操作，而且分组字段也刚好和索引键字段一致，那么mysqld 同样可以利用索引已经排好序的这个特性，省略掉分组中的排序操作。 排序分组操作主要消耗的是内存和 CPU 资源，如果能够在进行排序分组操作中利用好索引，将会极大地降低CPU资源的消耗。 索引的弊端索引的益处已经清楚了，但是我们不能只看到这些益处，并认为索引是解决 Query 优化的圣经，只要发现 Query 运行不够快就将 WHERE 子句中的条件全部放在索引中。 确实，索引能够极大地提高数据检索效率，也能够改善排序分组操作的性能，但有不能忽略的一个问题就是索引是完全独立于基础数据之外的一部分数据。假 设在Table ta 中的Column ca 创建了索引 idx_ta_ca，那么任何更新 Column ca 的操作，MySQL在更新表中 Column ca的同时，都须要更新Column ca 的索引数据，调整因为更新带来键值变化的索引信息。而如果没有对 Column ca 进行索引，MySQL要做的仅仅是更新表中 Column ca 的信息。这样，最明显的资源消耗就是增加了更新所带来的 IO 量和调整索引所致的计算量。此外，Column ca 的索引idx_ta_ca须要占用存储空间，而且随着 Table ta 数据量的增加，idx_ta_ca 所占用的空间也会不断增加，所以索引还会带来存储空间资源消耗的增加。 如何判定是否须要创建索引在了解了索引的利与弊之后，那我们到底该如何来判断某个索引是否应该创建呢？ 实际上，并没有一个非常明确的定律可以清晰地定义什么字段应该创建索引，什么字段不该创建索引。因为应用场景实在是太复杂，存在太多的差异。当然，还是仍然能够找到几点基本的判定策略来帮助分析的。 1. 较频繁的作为查询条件的字段应该创建索引提高数据查询检索的效率最有效的办法就是减少须要访问的数据量，从上面索引的益处中我们知道，索引正是减少通过索引键字段作为查询条件的 Query 的IO量之最有效手段。所以一般来说应该为较为频繁的查询条件字段创建索引。 2. 唯一性太差的字段不适合单独创建索引，即使频繁作为查询条件唯一性太差的字段主要是指哪些呢？如状态字段、类型字段等这些字段中存放的数据可能总共就是那么几个或几十个值重复使用，每个值都会存在于成千上万 或更多的记录中。对于这类字段，完全没有必要创建单独的索引。因为即使创建了索引，MySQL Query Optimizer 大多数时候也不会去选择使用，如果什么时候 MySQL Query Optimizer选择了这种索引，那么非常遗憾地告诉你，这可能会带来极大的性能问题。由于索引字段中每个值都含有大量的记录，那么存储引擎在根据索引 访问数据的时候会带来大量的随机IO，甚至有些时候还会出现大量的重复IO。 这主要是由于数据基于索引扫描的特点引起的。当我们通过索引访问表中数据时，MySQL 会按照索引键的键值顺序来依序访问。一般来说，每个数据页中大都会存放多条记录，但是这些记录可能大多数都不会和你所使用的索引键的键值顺序一致。 假如有以下场景，我们通过索引查找键值为A和B的某些数据。在通过A键值找到第一条满足要求的记录后，会读取这条记录所在的 X 数据页，然后继续往下查找索引，发现 A 键值所对应的另外一条记录也满足要求，但是这条记录不在 X 数据页上，而在Y数据页上，这时候存储引擎就会丢弃X数据页，而读取Y数据页。如此继续一直到查找完A键值所对应的所有记录。然后轮到B键值了，这时发现 正在查找的记录又在X数据页上，可之前读取的 X 数据页已经被丢弃了，只能再次读取 X 数据页。这时候，实际上已经重复读取 X 数据页两次了。在继续往后的查找中，可能还会出现一次又一次的重复读取，这无疑给存储引擎极大地增加了IO访问量。 不仅如此，如果一个键值对应了太多的数据记录，也就是说通过该键值会返回占整个表比例很大的记录时，由于根据索引扫描产生的都是随机 IO，其效率比进行全表扫描的顺序IO效率低很多，即使不会出现重复 IO 的读取，同样会造成整体 IO 性能的下降。 很多比较有经验的 Query 调优专家经常说，当一条Query返回的数据超过了全表的 15%时，就不应该再使用索引扫描来完成这个 Query 了。对于”15%”这个数字我们并不能判定是否很准确，但是至少侧面证明了唯一性太差的字段并不适合创建索引。 3. 更新非常频繁的字段不适合创建索引上面在索引的弊端中已经分析过了，索引中的字段被更新的时候，不仅要更新表中的数据，还要更新索引数据，以确保索引信息是准确的。这个问题致使IO 访问量较大增加，不仅仅影响了更新 Query 的响应时间，还影响了整个存储系统的资源消耗，加大了整个存储系统的负载。 当然，并不是存在更新的字段就适合创建索引，从判定策略的用语上也可以看出，是”非常频繁”的字段。到底什么样的更新频率应该算是”非常频繁”呢？ 每秒？每分钟？还是每小时呢？说实话，还真难定义。很多时候是通过比较同一时间段内被更新的次数和利用该字段作为条件的查询次数来判断的，如果通过该字段 的查询并不是很多，可能几个小时或是更长才会执行一次，更新反而比查询更频繁，那这样的字段肯定不适合创建索引。反之，如果我们通过该字段的查询比较频 繁，但更新并不是特别多，比如查询几十次或更多才可能会产生一次更新，那我个人觉得更新所带来的附加成本也是可以接受的。 4. 不会出现在 WHERE 子句中的字段不该创建索引不会还有人会问为什么吧？自己也觉得这是废话了，哈哈！ 单键索引还是组合索引在大概了解了MySQL 各种类型的索引，以及索引本身的利弊与判断一个字段是否须要创建索引之后，就要着手创建索引来优化Query 了。在很多时候，WHERE 子句中的过滤条件并不只是针对于单一的某个字段，经常会有多个字段一起作为查询过滤条件存在于 WHERE 子句中。在这种时候，就必须要判断是该仅仅为过滤性最好的字段建立索引，还是该在所有字段（过滤条件中的）上建立一个组合索引。 对于这种问题，很难有一个绝对的定论，须要从多方面来分析考虑，平衡两种方案各自的优劣，然后选择一种最佳的方案。因为从上一节中已了解到索引在提 高某些查询的性能同时，也会让某些更新的效率下降。而组合索引中因为有多个字段存在，理论上被更新的可能性肯定比单键索引要大很多，这样带来的附加成本也 就比单键索引要高。但是，当WHERE 子句中的查询条件含有多个字段时，通过这多个字段共同组成的组合索引的查询效率肯定比只用过滤条件中的某一个字段创建的索引要高。因为通过单键索引过滤的 数据并不完整，和组合索引相比，存储引擎须要访问更多的记录数，自然就会访问更多的数据量，也就是说需要更高的 IO 成本。 可能有朋友会说，那可以创建多个单键索引啊。确实可以将 WHERE 子句中的每一个字段都创建一个单键索引。但是这样真的有效吗？在这样的情况下，MySQL Query Optimizer 大多数时候都只会选择其中的一个索引，然后放弃其他的索引。即使他选择了同时利用两个或更多的索引通过 INDEX_MERGE 来优化查询，所收到的效果可能并不会比选择其中某一个单键索引更高效。因为如果选择通过 INDEX_MERGE 来优化查询，就须要访问多个索引，同时还要将几个索引进行 merge 操作，这带来的成本可能反而会比选择其中一个最有效的索引更高。 在一般的应用场景中，只要不是其中某个过滤字段在大多数场景下能过滤90%以上的数据，而其他的过滤字段会频繁的更新，一般更倾向于创建组合索引， 尤其是在并发量较高的场景下。因为当并发量较高的时候，即使只为每个Query节省了很少的 IO 消耗，但因为执行量非常大，所节省的资源总量仍然是非常可观的。 当然，创建组合索引并不是说就须要将查询条件中的所有字段都放在一个索引中，还应该尽量让一个索引被多个 Query 语句利用，尽量减少同一个表上的索引数量，减少因为数据更新带来的索引更新成本，同时还可以减少因为索引所消耗的存储空间。 此外，MySQL 还提供了另外一个优化索引的功能，那就是前缀索引。在 MySQL 中，可以仅仅使用某个字段的前面部分内容做为索引键索引该字段，以达到减小索引占用的存储空间和提高索引访问效率的目的。当然，前缀索引的功能仅仅适用于 字段前缀随机重复性很小的字段。如果须要索引的字段前缀内容有较多的重复，索引的过滤性自然也会随之降低，通过索引所访问的数据量就会增加，这时候前缀索 引虽然能够减少存储空间消耗，但是可能会造成 Query 访问效率的极大降低，得不偿失。 复合索引优化两个或更多个列上的索引被称作复合索引。利用索引中的附加列，您可以缩小搜索的范围，但使用一个具有两列的索引不同于使用两个单独的索引。复合索引的结构与电话簿类似，人名由姓和名构成，电话簿 首先按姓氏对进行排序，然后按名字对有相同姓氏的人进行排序。如果您知道姓，电话簿将非常有用；如果您知道姓和名，电话簿则更为有用，但如果您只知道名不 姓，电话簿将没有用处。所以说创建复合索引时，应该仔细考虑列的顺序。对索引中的所有列执行搜索或仅对前几列执行搜索时，复合索引非常有用；仅对后面的任意列执行搜索时，复合索引则没有用处。如：建立 姓名、年龄、性别的复合索引。复合索引的建立原则：如果您很可能仅对一个列多次执行搜索，则该列应该是复合索引中的第一列。如果您很可能对一个两列索引中的两个列执行单独的搜索，则应该创建另一个仅包含第二列的索引。如上图所示，如果查询中需要对年龄和性别做查询，则应当再新建一个包含年龄和性别的复合索引。包含多个列的主键始终会自动以复合索引的形式创建索引，其列的顺序是它们在表定义中出现的顺序，而不是在主键定义中指定的顺序。在考虑将来通过主键执行的搜索，确定哪一列应该排在最前面。请注意，创建复合索引应当包含少数几个列，并且这些列经常在select查询里使用。在复合索引里包含太多的列不仅不会给带来太多好处。而且由于使用相当多的内存来存储复合索引的列的值，其后果是内存溢出和性能降低。复合索引对排序的优化：复合索引只对和索引中排序相同或相反的order by 语句优化。在创建复合索引时，每一列都定义了升序或者是降序。如定义一个复合索引： Sql代码 CREATE INDEX idx_example ON table1 (col1 ASC, col2 DESC, col3 ASC) 其中 有三列分别是：col1 升序，col2 降序， col3 升序。现在如果我们执行两个查询 1Select col1, col2, col3 from table1 order by col1 ASC, col2 DESC, col3 ASC 和索引顺序相同 1Select col1, col2, col3 from table1 order by col1 DESC, col2 ASC, col3 DESC 和索引顺序相反 查询1，2 都可以别复合索引优化。 如果查询为： 1Select col1, col2, col3 from table1 order by col1 ASC, col2 ASC, col3 ASC 排序结果和索引完全不同时，此时的查询不会被复合索引优化。 查询优化器在在where查询中的作用： 如果一个多列索引存在于 列 Col1 和 Col2 上，则以下语句：Select * from table where col1=val1 AND col2=val2 查询优化器会试图通过决定哪个索引将找到更少的行。之后用得到的索引去取值。 1． 如果存在一个多列索引，任何最左面的索引前缀能被优化器使用。所以联合索引的顺序不同，影响索引的选择，尽量将值少的放在前面。 如：一个多列索引为 (col1 ，col2， col3) ​ 那么在索引在列 (col1) 、(col1 col2) 、(col1 col2 col3) 的搜索会有作用。 Sql代码 1231. SELECT * FROM tb WHERE col1 = val1 2. SELECT * FROM tb WHERE col1 = val1 and col2 = val2 3. SELECT * FROM tb WHERE col1 = val1 and col2 = val2 AND col3 = val3 2． 如果列不构成索引的最左面前缀，则建立的索引将不起作用。如： 1231. SELECT * FROM tb WHERE col3 = val3 2. SELECT * FROM tb WHERE col2 = val2 3. SELECT * FROM tb WHERE col2 = val2 and col3=val3 3． 如果一个 Like 语句的查询条件不以通配符起始则使用索引。 如：%车 或 %车% 不使用索引。 ​ 车% 使用索引。 索引的缺点： 占用磁盘空间。 增加了插入和删除的操作时间。一个表拥有的索引越多，插入和删除的速度越慢。如 要求快速录入的系统不宜建过多索引。 下面是一些常见的索引限制问题 1、使用不等于操作符(&lt;&gt;, !=) 下面这种情况，即使在列dept_id有一个索引，查询语句仍然执行一次全表扫描 1select * from dept where staff_num &lt;&gt; 1000; 但是开发中的确需要这样的查询，难道没有解决问题的办法了吗？ 有！ 通过把用 or 语法替代不等号进行查询，就可以使用索引，以避免全表扫描：上面的语句改成下面这样的，就可以使用索引了。 Sql代码 1select * from dept shere staff_num &lt; 1000 or dept_id &gt; 1000; 2、使用 is null 或 is not null 使用 is null 或is nuo null也会限制索引的使用，因为数据库并没有定义null值。如果被索引的列中有很多null，就不会使用这个索引（除非索引是一个位图索引，关于位图 索引，会在以后的blog文章里做详细解释）。在sql语句中使用null会造成很多麻烦。 解决这个问题的办法就是：建表时把需要索引的列定义为非空(not null) 3、使用函数 如果没有使用基于函数的索引，那么where子句中对存在索引的列使用函数时，会使优化器忽略掉这些索引。下面的查询就不会使用索引： 1select * from staff where trunc(birthdate) = &apos;01-MAY-82&apos;; 但是把函数应用在条件上，索引是可以生效的，把上面的语句改成下面的语句，就可以通过索引进行查找。 1select * from staff where birthdate &lt; (to_date(&apos;01-MAY-82&apos;) + 0.9999); 4、比较不匹配的数据类型 比较不匹配的数据类型也是难于发现的性能问题之一。 下面的例子中，dept_id是一个varchar2型的字段，在这个字段上有索引，但是下面的语句会执行全表扫描。 1select * from dept where dept_id = 900198; 这是因为oracle会自动把where子句转换成to_number(dept_id)=900198，就是3所说的情况，这样就限制了索引的使用。 把SQL语句改为如下形式就可以使用索引 1select * from dept where dept_id = &apos;900198&apos;; 恩，这里还有要注意的： 比方说有一个文章表，我们要实现某个类别下按时间倒序列表显示功能： 1SELECT * FROM articles WHERE category_id = ... ORDER BY created DESC LIMIT ... 这样的查询很常见，基本上不管什么应用里都能找出一大把类似的SQL来，学院派的读者看到上面的SQL，可能会说SELECT *不好，应该仅仅查询需要的字段，那我们就索性彻底点，把SQL改成如下的形式： 1SELECT id FROM articles WHERE category_id = ... ORDER BY created DESC LIMIT ... 我们假设这里的id是主键，至于文章的具体内容，可以都保存到memcached之类的键值类型的缓存里，如此一来，学院派的读者们应该挑不出什么毛病来了，下面我们就按这条SQL来考虑如何建立索引： 不考虑数据分布之类的特殊情况，任何一个合格的WEB开发人员都知道类似这样的SQL，应该建立一个”category_id, created“复合索引，但这是最佳答案不？不见得，现在是回头看看标题的时候了：MySQL里建立索引应该考虑数据库引擎的类型！ 如果我们的数据库引擎是InnoDB，那么建立”category_id, created“复合索引是最佳答案。让我们看看InnoDB的索引结构，在InnoDB里，索引结构有一个特殊的地方：非主键索引在其BTree的叶节 点上会额外保存对应主键的值，这样做一个最直接的好处就是Covering Index，不用再到数据文件里去取id的值，可以直接在索引里得到它。 如果我们的数据库引擎是MyISAM，那么建立”category_id, created”复合索引就不是最佳答案。因为MyISAM的索引结构里，非主键索引并没有额外保存对应主键的值，此时如果想利用上Covering Index，应该建立”category_id, created, id”复合索引。 唠完了，应该明白我的意思了吧。希望以后大家在考虑索引的时候能思考的更全面一点，实际应用中还有很多类似的问题，比如说多数人在建立索引的时候不从 Cardinality（SHOW INDEX FROM …能看到此参数）的角度看是否合适的问题，Cardinality表示唯一值的个数，一般来说，如果唯一值个数在总行数中所占比例小于20%的话，则 可以认为Cardinality太小，此时索引除了拖慢insert/update/delete的速度之外，不会对select产生太大作用；还有一个 细节是建立索引的时候未考虑字符集的影响，比如说username字段，如果仅仅允许英文，下划线之类的符号，那么就不要用gbk，utf-8之类的字符 集，而应该使用latin1或者ascii这种简单的字符集，索引文件会小很多，速度自然就会快很多。这些细节问题需要读者自己多注意，我就不多说了。 摘自：MySQL性能调优与架构设计 转载：https://blog.csdn.net/linminqin/article/details/44342205 MySQL 性能优化神器 Explain 使用分析MySQL 提供了一个 EXPLAIN 命令, 它可以对 SELECT 语句进行分析, 并输出 SELECT 执行的详细信息, 以供开发人员针对性优化. EXPLAIN 命令用法十分简单, 在 SELECT 语句前加上 Explain 就可以了。 参考：MySQL 性能优化神器 Explain 使用分析","tags":[{"name":"Mysql 索引","slug":"Mysql-索引","permalink":"http://blog.pcluo.com/tags/Mysql-索引/"}]},{"title":"SpringMVC 启动初始化过程分析","date":"2018-05-14T09:42:56.000Z","path":"2018/05/14/SpringMVC-启动初始化过程分析/","text":"SpringMVC 启动初始化过程分析之前我们写过Servlet的生命周期分析，在这个基础上，我们来看看SpringMVC启动过程中是如何出事化的，它都做了哪些事情。 先来看看SpringMVC核心ServletDispatcherServlet。看下他的继承关系： 我们可以看到他的顶级接口是Servlet，这是必然的。所以我们从Servlet 的init 开始一步一步往下分析： –HttpServletBean.init() ​ –FrameworkServlet.initServletBean() ​ .initWebApplicationContext() ​ –DispatcherServlet.onRefresh() ​ .initStrategies() 12345678910111213RequestMappingHandlerMapping.class@Overrideprotected boolean isHandler(Class&lt;?&gt; beanType) &#123; return (AnnotatedElementUtils.hasAnnotation(beanType, Controller.class) || AnnotatedElementUtils.hasAnnotation(beanType, RequestMapping.class));&#125;AbstractHandlerMethodMapping.classprotected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method);&#125; 91","tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://blog.pcluo.com/tags/SpringMVC/"}]},{"title":"Spring-Cloud微服务架构（四）服务网关","date":"2018-05-09T15:49:32.000Z","path":"2018/05/09/Spring-Cloud微服务架构（四）服务网关/","text":"之前，我们已经初步完成了一个简易版的微服务分布式系统了。我们使用Spring Cloud Netflix中的Eureka实现了服务注册中心以及服务注册与发现；而服务间通过Ribbon或Feign实现服务的消费以及均衡负载；为了使得服务集群更为健壮，使用Hystrix的融断机制来避免在微服务架构中个别服务出现异常时引起的故障蔓延。 在该架构中，我们的服务集群包含：内部服务Pay Server和Provider Server，他们都会注册与订阅服务至Eureka Server，这里还有个对外提供的一个服务，这个服务通过负载均衡提供调用服务Pay Server和服务Provider Server的方法，本文我们把焦点聚集在对外服务这块，这样的实现是否合理，或者是否有更好的实现方式呢？ 先来说说这样架构需要做的一些事儿以及存在的不足： 首先，破坏了服务无状态特点。为了保证对外服务的安全性，我们需要实现对服务访问的权限控制，而开放服务的权限控制机制将会贯穿并污染整个开放服务的业务逻辑，这会带来的最直接问题是，破坏了服务集群中REST API无状态的特点。从具体开发和测试的角度来说，在工作中除了要考虑实际的业务逻辑之外，还需要额外可续对接口访问的控制处理。 其次，无法直接复用既有接口。当我们需要对一个即有的集群内访问接口，实现外部服务访问时，我们不得不通过在原有接口上增加校验逻辑，或增加一个代理调用来实现权限控制，无法直接复用原有的接口。 面对类似上面的问题，我们要如何解决呢？下面进入本文的正题：服务网关！ 为了解决上面这些问题，我们需要将权限控制这样的东西从我们的服务单元中抽离出去，而最适合这些逻辑的地方就是处于对外访问最前端的地方，我们需要一个更强大一些的均衡负载器，它就是本文将来介绍的：服务网关。 服务网关是微服务架构中一个不可或缺的部分。通过服务网关统一向外系统提供REST API的过程中，除了具备服务路由、均衡负载功能之外，它还具备了权限控制等功能。Spring Cloud Netflix中的Zuul就担任了这样的一个角色，为微服务架构提供了前门保护的作用，同时将权限控制这些较重的非业务逻辑内容迁移到服务路由层面，使得服务集群主体能够具备更高的可复用性和可测试性。 下面我们通过实例例子来使用一下Zuul来作为服务的路有功能。 开始使用Zuul1、创建一个Web Gateway服务，引入pom.xml 所需要的依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.blog&lt;/groupId&gt; &lt;artifactId&gt;web-gateway&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;web-gateway&lt;/name&gt; &lt;description&gt;web-gateway&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RC1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- zuul --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务消费者 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 2、在主应用类上开启zuul，加入注解@EnableZuulProxy 123456789101112131415161718@EnableZuulProxy@EnableEurekaClient@SpringCloudApplicationpublic class WebGatewayApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate()&#123; SimpleClientHttpRequestFactory simpleClientHttpRequestFactory = new SimpleClientHttpRequestFactory (); simpleClientHttpRequestFactory.setConnectTimeout(10000); simpleClientHttpRequestFactory.setReadTimeout(10000); return new RestTemplate(simpleClientHttpRequestFactory); &#125; public static void main(String[] args) &#123; SpringApplication.run(WebGatewayApplication.class, args); &#125;&#125; 3、在application.yml中配置zuul 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748server: port: 9400eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: web-gatewaypay-server: ribbon:# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮调 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRuleprovider-server: ribbon:# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮调 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule##断路器 将 hystrix 的超时时间设置成 60000 毫秒（60秒）hystrix: command: default: execution: timeout: enabled: false isolation: thread: timeoutInMilliseconds: 60000# zuulzuul: host: socket-timeout-millis: 60000 connect-timeout-millis: 60000 routes: api-pay: path: /pay/**# url: http://localhost:9200/ serviceId: pay-server api-provider: path: /provider/** serviceId: provider-server zuul 配置介绍 服务路由通过服务路由的功能，我们在对外提供服务的时候，只需要通过暴露Zuul中配置的调用地址就可以让调用方统一的来访问我们的服务，而不需要了解具体提供服务的主机信息了。 在Zuul中提供了两种映射方式： 通过url直接映射，我们可以如下配置：（实际项目中不推荐使用） 123456789101112# zuulzuul: host: socket-timeout-millis: 60000 connect-timeout-millis: 60000 routes: api-pay: path: /pay/** url: http://localhost:9200/ api-provider: path: /provider/** url: http://localhost:9300/ 该配置中将所有的/pay/**的访问映射到http://localhost:9200/上，也就是说当我们访问http://localhost:9400/pay/api/pay/testPay的时候，Zuul会将该请求路由到：http://localhost:9200/api/pay/testPay上。 其中，配置属性zuul.routes.api-pay.path中的api-pay部分为路由的名字，可以任意定义，但是一组映射关系的path和url要相同，下面讲serviceId时候也是如此。 通过serviceId映射（推荐配置） 通过url映射的方式对于Zuul来说，并不是特别友好，Zuul需要知道我们所有为服务的地址，才能完成所有的映射配置。而实际上，我们在实现微服务架构是，服务名与服务实例地址的关系在Eureka Server中已经存在了，所以只需要将Zuul注册到Eureka Server上去发现其他服务，我们就可以实现对serviceId的映射。例如，我们可以如下配置： 123456789101112# zuulzuul: host: socket-timeout-millis: 60000 connect-timeout-millis: 60000 routes: api-pay: path: /pay/** serviceId: pay-server api-provider: path: /provider/** serviceId: provider-server 这里我们说明下为什么推荐使用这种配置。当我们整个系统运行起来的时候，肯定会把我们一个个的服务集群化，这样我们使用直接的url映射，将无法进行负载均衡。也就容易出现某一台服务器的负载过高，而其他服务器空闲，资源浪费。 下面，我们就来演示一下效果，分别启动Eureka Server、Pay Server、Provider Server、Web Gateway四个服务。 然后我们同过服务网关来访问Pay Server、Provider Server，根据配置的映射关系，分别访问下面的url http://localhost:9400/pay/api/pay/testPay：通过serviceId映射访问Pay Server中的testPay服务 http://localhost:9400/provider/api/provider/testProvider：通过serviceId映射访问Provider Server中的testProvider服务 访问结果 服务过滤在完成了服务路由之后，我们对外开放服务还需要一些安全措施来保护客户端只能访问它应该访问到的资源。所以我们需要利用Zuul的过滤器来实现我们对外服务的安全控制。 在服务网关中定义过滤器只需要继承ZuulFilter抽象类实现其定义的四个抽象函数就可对请求进行拦截与过滤。 比如下面的例子，定义了一个Zuul过滤器，实现了在请求被路由之前检查请求中是否有accessToken参数，若有就进行路由，若没有就拒绝访问，返回401 Unauthorized错误。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ZuulPreFilter extends ZuulFilter &#123; private static Logger log = LoggerFactory.getLogger(ZuulPreFilter.class); /** * ZuulFilter 的类型 * @return */ @Override public String filterType() &#123; return \"pre\"; &#125; /** * 执行顺序控制 * @return */ @Override public int filterOrder() &#123; return 0; &#125; /** * 返回一个boolean类型来判断该过滤器是否要执行，所以通过此函数可实现过滤器的开关。我们直接返回true，所以该过滤器总是生效。 * @return */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * 过滤器的具体逻辑。这里我们通过ctx.setSendZuulResponse(false)令zuul过滤该请求，不对其进行路由， * 然后通过ctx.setResponseStatusCode(401)设置了其返回的错误码， * 当然我们也可以进一步优化我们的返回，比如，通过ctx.setResponseBody(body)对返回body内容进行编辑等。 */ @Override public Object run() throws ZuulException &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); log.info(String.format(\"%s request to %s\", request.getMethod(), request.getRequestURL().toString())); Object accessToken = request.getParameter(\"accessToken\"); if(accessToken == null) &#123; log.warn(\"access token is empty\"); ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(401); ctx.setResponseBody(\"access token is empty\"); return null; &#125; log.info(\"access token ok\"); return null; &#125;&#125; 实现了自定义过滤器之后，向容器中注入ZuulPreFilter 123456789101112131415161718192021222324252627@EnableZuulProxy@EnableEurekaClient@SpringCloudApplicationpublic class WebGatewayApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate() &#123; SimpleClientHttpRequestFactory simpleClientHttpRequestFactory = new SimpleClientHttpRequestFactory(); simpleClientHttpRequestFactory.setConnectTimeout(10000); simpleClientHttpRequestFactory.setReadTimeout(10000); return new RestTemplate(simpleClientHttpRequestFactory); &#125; /** * 加入ZuulPreFilter */ @Bean public ZuulPreFilter zuulPreFilter() &#123; return new ZuulPreFilter(); &#125; public static void main(String[] args) &#123; SpringApplication.run(WebGatewayApplication.class, args); &#125;&#125; 重新启动我们的Web Gateway服务，访问http://localhost:9400/pay/api/pay/testPay：状态码401，响应体access token is empty访问http://localhost:9400/pay/api/pay/testPay?accessToken=xxx：状态码200，响应体test，访问成功对于其他一些过滤类型，这里就不一一展开了，根据之前对filterType生命周期介绍，可以参考下图去理解，并根据自己的需要在不同的生命周期中去实现不同类型的过滤器。最后，总结一下为什么服务网关是微服务架构的重要部分，是我们必须要去做的原因： 不仅仅实现了路由功能来屏蔽诸多服务细节，更实现了服务级别、均衡负载的路由。 实现了接口权限校验与微服务业务逻辑的解耦。通过服务网关中的过滤器，在各生命周期中去校验请求的内容，将原本在对外服务层做的校验前移，保证了微服务的无状态性，同时降低了微服务的测试难度，让服务本身更集中关注业务逻辑的处理。 实现了断路器，不会因为具体微服务的故障而导致服务网关的阻塞，依然可以对外服务。","tags":[{"name":"API GateWay","slug":"API-GateWay","permalink":"http://blog.pcluo.com/tags/API-GateWay/"}]},{"title":"Spring-Cloud微服务架构（三）断路器","date":"2018-05-09T08:51:51.000Z","path":"2018/05/09/Spring-Cloud微服务架构（三）断路器/","text":"在微服务架构中，我们把整个系统拆分成一个个的子服务，每个服务之间通过注册与订阅的方式进行相互依赖。每个服务在不同的进程中运行，通过远程调用的方式进行访问。这样就有可能因为网络原因或是依赖服务自身问题出现调用故障或延迟，而这些问题会直接导致调用方的对外服务也出现延迟，若此时调用方的请求不断增加，最后就会出现因等待出现故障的依赖方响应而形成任务积压，最终导致自身服务的瘫痪。形成服务器雪崩 如上图所示：A为服务提供者，B为A的服务调用者，C和D是B的服务调用者。当A的不可用，引起B的不可用，并将不可用逐渐放大C和D时，服务雪崩就形成了。 Netflix Hystrix断路器在Spring Cloud中使用了Hystrix 来实现断路器的功能。Hystrix是Netflix开源的微服务框架套件之一，该框架目标在于通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能。 继续之前的的两个服务来做断路器测试。 启动Eureka Server、Pay Server、Provider Server访问http://localhost:9200/api/pay/testProviderRibbon，调用Provider Server的服务，可以看到我们的测试返回 testProvider success。 然后我们关闭 Provider Server，在浏览器再次访问http://localhost:9200/api/pay/testProviderRibbon，我们得到报错信息。 1234567Whitelabel Error PageThis application has no explicit mapping for /error, so you are seeing this as a fallback.Wed May 09 23:06:29 CST 2018There was an unexpected error (type=Internal Server Error, status=500).I/O error on POST request for &quot;http://provider-server/api/provider/testProvider&quot;: Connection refused: connect; nested exception is java.net.ConnectException: Connection refused: connect 开启Pay Server服务的断路器功能，在住应用类PayServerApplication.java上加上@EnableCircuitBreaker，代码如下： 123456789101112131415@EnableEurekaClient@SpringCloudApplication@EnableFeignClients //Feign支持public class PayServerApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(PayServerApplication.class, args); &#125;&#125; 可以看到我们，没有加上这个注解。因为我们用的是@SpringCloudApplication这个注解，它里面包含了@EnableCircuitBreaker这个注解 123456789@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootApplication@EnableDiscoveryClient@EnableCircuitBreakerpublic @interface SpringCloudApplication &#123;&#125; Ribbon中使用Hystrix改造Pay Server 的TestPayController.java 类，在接口testProviderRibbon加入注解@HystrixCommand，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@RestController@RequestMapping(\"/api/pay\")public class TestPayController &#123; private final static Logger log = LoggerFactory.getLogger(TestPayController.class); @Autowired private DiscoveryClient client; @Autowired private ProviderFeginCustomClient feignClient; @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; @RequestMapping(\"/testPay\") public String testPay()&#123; List&lt;ServiceInstance&gt; instances = client.getInstances(\"pay-server\"); ServiceInstance instance = instances.get(0); log.info(\"/testPay, host:\" + instance.getHost() + \", service_id:\" + instance.getServiceId()); return \"test\"; &#125; @RequestMapping(\"/testProviderFeign\") public String testProviderFeign()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"testProviderFeign &gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return feignClient.testProvider(); &#125; @RequestMapping(\"/testProviderRibbon\") @HystrixCommand(fallbackMethod = \"testProviderRibbonFallback\") public String testProviderRibbon()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); &#125; private String testProviderRibbonFallback()&#123; return \"error\"; &#125;&#125; 可以看到我们现在已经在 testProviderRibbon方法上加上了注解，并且添加了一个回调方法。 现在，我们重新启动Pay Server，也就是我们只启动Eureka Server和Pay Server两个服务，再次访问http://localhost:9200/api/pay/testProviderRibbon，我们可以看到页面显示：error Feign中使用Hystrix1、Feign 是默认关闭 Hystrix的，所以我们要在配置里打开它，修改Pay Server的application.yml 1234567891011121314151617181920212223242526272829303132333435---server: port: 9200eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: pay-server profiles: peer1provider-server: ribbon:# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮调 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRulefeign: hystrix: enabled: true##断路器 将 hystrix 的超时时间设置成 60000 毫秒（60秒）hystrix: command: default: execution: timeout: enabled: false isolation: thread: timeoutInMilliseconds: 60000 也就是添加了feign.hystrix.enabled=true 这个属性。 2、创建类ProviderFeginCustomClientFallback.java，并且实现ProviderFeginCustomClient.java 12345678@Componentpublic class ProviderFeginCustomClientFallback implements ProviderFeginCustomClient &#123; @Override public String testProvider() &#123; return \"errorFeign\"; &#125;&#125; 3、修改ProviderFeginCustomClient.java，在@FeignClient中添加属性 fallback，并配置为ProviderFeginCustomClientFallback。 12345678@FeignClient(name = \"provider-server\", fallback = ProviderFeginCustomClientFallback.class)public interface ProviderFeginCustomClient &#123; @RequestMapping(value = \"/api/provider/testProvider\", method = RequestMethod.GET) public String testProvider();&#125; 现在，我们重新启动Pay Server，也就是我们只启动Eureka Server和Pay Server两个服务，在浏览器访问http://localhost:9200/api/pay/testProviderFeign，我们可以看到页面显示：errorFeign","tags":[{"name":"Hystrix","slug":"Hystrix","permalink":"http://blog.pcluo.com/tags/Hystrix/"}]},{"title":"Spring Cloud微服务架构（二）服务消费者","date":"2018-05-07T11:36:11.000Z","path":"2018/05/07/Spring-Cloud微服务架构（二）服务消费者/","text":"在上一篇中《Spring Cloud微服务架构（一）高可用服务注册与发现》中，我们已经创建了服务注册中心，并且注册了一个服务提供者 pay-server，那么接下来我们要怎么去消费提供者提供的接口呢？ 首先创建 Provider Server 服务提供方创建一个基本的Provider Server 项目，在pom.xml 引入以下依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.blog&lt;/groupId&gt; &lt;artifactId&gt;provider-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;provider-server&lt;/name&gt; &lt;description&gt;provider-server&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RC1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 创建好Provider Server 项目后，主应用类将@SpringBootApplication修改为SpringCloudApplication注解，将此服务注册到Eureka Server中，代码如下： 12345678@EnableEurekaClient@SpringCloudApplicationpublic class ProviderServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderServerApplication.class, args); &#125;&#125; 配置application.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344---server: port: 9300eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: provider-server profiles: peer1---server: port: 9301eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: provider-server profiles: peer2---server: port: 9302eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: provider-server profiles: peer3 这里有三个配置，用来测试我们的负载均衡，服务调用方具体是访问的是那个端口下的服务。 接下来编写一个提供其他服务调用的接口，这里也就是我们的Pay Server来调用，代码如下： 1234567891011121314151617@RestController@RequestMapping(\"/api/provider\")public class TestProviderController &#123; private final static Logger log = LoggerFactory.getLogger(TestProviderController.class); @Autowired private LoadBalancerClient loadBalancerClient; @RequestMapping(\"testProvider\") public String testProvider()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return \"testProvider success\"; &#125;&#125; 到此，服务提供方就已经做好了。 RibbonRibbon 是一个客户端负载均衡器，可以让您对HTTP和TCP客户端的行为有很多控制权。Feign已经使用Ribbon，因此，如果您使用@FeignClient，此部分也适用。原理我们这里就不做过多说明，直接进入实战演练。 下面我们通过实例看看如何使用Ribbon来调用服务，并实现客户端的均衡负载。 上面，我们已经创建好了Provider Server服务提供方，在Pay Server中使用Ribbon来进行消费。 1、在pom.xml 中引入新的依赖12345678910&lt;!-- 服务消费者 ribbon openfeign 这里直接把两个依赖都加上 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 2、修改Pay Server主应用类：1234567891011121314@EnableEurekaClient@SpringCloudApplicationpublic class PayServerApplication &#123; @Bean @LoadBalanced //开启负载均衡 RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(PayServerApplication.class, args); &#125;&#125; 3、创建TestPayController.java 来消费Provider Server的 testProvider 服务，通过直接RestTemplate来调用服务。1234567891011121314151617181920212223@RestController@RequestMapping(\"/api/pay\")public class TestPayController &#123; private final static Logger log = LoggerFactory.getLogger(TestPayController.class); @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; /** * Ribbon方式访问 */ @RequestMapping(\"/testProviderRibbon\") public String testProviderRibbon()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); &#125;&#125; 4、修改application.yml123456789101112131415161718192021222324252627282930---server: port: 9200eureka: client: service-url: defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: name: pay-server profiles: peer1provider-server: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #轮询# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #随机分配# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule #加权响应时间# 断路器 将 hystrix 的超时时间设置成 60000 毫秒（60秒）# 解决第一次请求报超时异常的方案，因为 hystrix 的默认超时时间是 1 秒，因此请求超过该时间后，就会出现页面超时显示 ：hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 60000 以上工作做完之后，我们就可以启动Pay Server和Provider Server了。将Provider Server分别根据配置启动三次（Spring Cloud微服务架构（一）高可用服务注册与发现 有说明如何根据不同配置启动）。启动后如下图接下来我们访问http://localhost:9200/api/pay/testProviderRibbon（也就是我们Pay Server的接口），查看日志和访问结果。调用日志：访问结果：我们可以看到，按顺序访问的端口服务器，这是因为我们在配置负载均衡的时候使用的是轮询模式。修改负载均衡模式（这次我们使用随机分配模式），我们在次调用。调用日志： 可以发现，现在调用的端口服务器是随机的。这里，通过Ribbon的方式来消费服务的方式就已经做好了。 Feign之前我们做Ribbon的时候，已经做了很多的准备工作，并且已经在pom.xml 文件中新添加了Feign 的依赖，所以这里我们直接开始。 1、添加访问远端服务 Feign 客户端ProviderFeginCustomClient.java，代码如下：1234567@FeignClient(name = \"provider-server\")public interface ProviderFeginCustomClient &#123; @RequestMapping(value = \"/api/provider/testProvider\", method = RequestMethod.GET) public String testProvider();&#125; 2、在TestProviderController.java中添加 Feign 方式访问的接口，代码如下：123456789101112131415161718192021222324252627282930313233343536@RestController@RequestMapping(\"/api/pay\")public class TestPayController &#123; private final static Logger log = LoggerFactory.getLogger(TestPayController.class); @Autowired private ProviderFeginCustomClient feignClient; @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; /** * Feign方式访问 */ @RequestMapping(\"/testProviderFeign\") public String testProviderFeign()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"testProviderFeign &gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return feignClient.testProvider(); &#125; /** * Ribbon方式访问 */ @RequestMapping(\"/testProviderRibbon\") public String testProviderRibbon()&#123; ServiceInstance instance = this.loadBalancerClient.choose(\"provider-server\"); log.info(\"&gt;&gt;&gt;&gt;&gt;\" + \" \" + instance.getServiceId() + \":\" + instance.getHost() + \":\" + instance.getPort()); return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); &#125;&#125; 重新启动Pay Server服务，访问http://localhost:9200/api/pay/testProviderFeign。调用日志：访问结果：根据日志和访问结果，我们的Feign 是配置成功了。这里的端口很明显是随机的，应为我们在做Ribbon的时候将它设置成了随机的负载均衡调度。到此Ribbon和Feign的服务消费就结束了。 那么，我们在开发的时候会想，到底使用Ribbon呢，还是Feign呢？ 现在我们就来分析一波，从代码上来看，我们使用Ribbon很方便快捷，只要在服务主应用类上加入下面一段代码。12345@Bean@LoadBalanced //开启负载均衡RestTemplate restTemplate()&#123; return new RestTemplate();&#125; 然后使用的时候，只要在其中注入 RestTemplate即可使用，通过调用RestTemplate的接口即可，例如下面的代码片 1return restTemplate.postForObject(\"http://provider-server/api/provider/testProvider\", null, String.class); 反观Feign，需要创建一个 Feign 客户端甚至是Feign 的配置（此案例中还未涉及Feign 的配置），显得旧没有那么方便快捷了。我们可以看到上面的 Feign 客户端ProviderFeginCustomClient.java，在调用的时候，注入Feign 客户端，直接调用接口即可，如下面的代码片段。 1return feignClient.testProvider(); 我们发现 Feign的调用方式就很像调用本地的方法，甚至感觉不到我们是在跨服务调用。 这里笔者的想法是这样的，在我们实际的项目中，如果我在消费者服务（这里也就是Pay Server）在不用过多的去调用提供方（这里也就是Provider Server）的接口时，我们倾向于使用Ribbon，因为它够方便，够简单。反之，我们倾向于使用Feign来做服务消费。我们可以看到Feign更具有封装性，将我们所有的服务调用，全部可以封装在 FeignClient 中，维护起来也方便。 我们可以一开始的时候使用Ribbon来做服务间的调用，之后变多的情况下，考虑代码重构。","tags":[{"name":"Ribbon","slug":"Ribbon","permalink":"http://blog.pcluo.com/tags/Ribbon/"},{"name":"Feign","slug":"Feign","permalink":"http://blog.pcluo.com/tags/Feign/"}]},{"title":"Spring Cloud微服务架构（一）高可用服务注册与发现","date":"2018-05-07T09:02:25.000Z","path":"2018/05/07/Spring-Cloud微服务架构（一）高可用服务注册与发现/","text":"创建“服务注册中心”创建一个基础的Spring Boot EurekaServer项目，在pom.xml 中引入需要的依赖​ 注意：在创建Spring Boot 项目时，版本的选择。本次系列文章均采用最新版本的2.0.1版本对应关系​ 为什么要在这里说明一下，因为不同的版本，你写的pom依赖可能不同。如下面的 服务注册依赖，​ 在Spring Boot 1.5.x 版本中 spring-cloud-starter-eureka-server 是这个，如何去找准确的依赖，要去​ 看官方文档，去里面找。如Spring Boot 2.0.1 Eureka Server 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.geeur.demo.cloud&lt;/groupId&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;description&gt;eureka-server&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.M9&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 服务注册 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 创建好EurekaServer 项目后，通过@EnableEurekaServer注解启动一个服务注册中心提供给其他应用进行对话。这一步只需要在你的Spring Boot 应用中添加这个注解，就可以开启此功能。代码如下： 12345678@EnableEurekaServer@SpringCloudApplicationpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 这里使用更改了创建项目时的@SpringBootApplication注解，变为@SpringCloudApplication，其实就是一个注解的整合，这里不做过多说明。 注意：使用@SpringCloudApplication时，需要加入断路器的依赖。使用@SpringBootApplication则可以不加断路器依赖，原因是@SpringCloudApplication注解里面包含@EnableCircuitBreaker这个注解，它需要断路器的自动配置。接下来就是application.yml 的配置(默认创建项目时生成的是application.properties 文件) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108# 测试环境 peer1---# 服务端口server: port: 9100eureka: server: # 正式环境不推荐加入此配置，以下server 配置为 Eureka Server的自我保护机制，在我们测试时候加入，是为了看效果 eviction-interval-timer-in-ms: 5000 enable-self-preservation: false client: # 是否向服务注册中心注册自己 register-with-eureka: true # 是否检索服务 fetch-registry: true serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: peer1 appname: $&#123;spring.application.name&#125; # 以下两个配置正式环境推荐使用默认值，不建议修改 # 表示eureka client间隔多久去拉取服务注册信息，默认为30秒，对于api-gateway，如果要迅速获取服务注册状态，可以缩小该值，比如5秒 lease-renewal-interval-in-seconds: 5 # 表示eureka server至上一次收到client的心跳之后，等待下一次心跳的超时时间，在这个时间内若没收到下一次心跳，则将移除该instance lease-expiration-duration-in-seconds: 10spring: application: # 微服务名称，后续在调用的时候只需要使用该名称就可以进行服务的访问 name: eureka-server profiles: peer1# 测试环境 peer2---server: port: 9101eureka: server: eviction-interval-timer-in-ms: 5000 enable-self-preservation: false client: register-with-eureka: true fetch-registry: true serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: peer2 appname: $&#123;spring.application.name&#125; lease-renewal-interval-in-seconds: 5 lease-expiration-duration-in-seconds: 10spring: application: name: eureka-server profiles: peer2# 测试环境 peer3---server: port: 9102eureka: server: eviction-interval-timer-in-ms: 5000 enable-self-preservation: false client: register-with-eureka: true fetch-registry: true serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: peer3 appname: $&#123;spring.application.name&#125; lease-renewal-interval-in-seconds: 5 lease-expiration-duration-in-seconds: 10spring: application: name: eureka-server profiles: peer3#生产环境推荐配置---server: port: 9103eureka: client: serviceUrl: defaultZone: http://peer1:9100/eureka/,http://peer2:9101/eureka/,http://peer3:9102/eureka/,http://prod:9103/eureka/ instance: instanceId: $&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125; prefer-ip-address: false hostname: prod appname: $&#123;spring.application.name&#125;spring: application: name: eureka-server profiles: prod 注意：这里需要在你们的 hosts 文件中加入如下配置 123127.0.0.1 peer1127.0.0.1 peer2127.0.0.1 peer3 因为我们要做Eureka Server 的集群，所以这个在我的application.yml 配置中，分别有三个配置peer1、peer2、peer3。然后我们启动Eureka Server 三次，根据不同的配置，在IDEA 中如何启动这三个配置。 修改Program arguments: –spring.profiles.active=peer1、 –spring.profiles.active=peer2、–spring.profiles.active=peer3，启动三次即可。任意访问其中一个： 可以看到我们的集群已经搭建好了。这里我们为什么要注册自己（register-with-eureka: true和fetch-registry: true这两个配置），我们可以看到下面那个红框中的数据，registered-replicas（注册副本）、unavailable-replicas（不可用副本）、available-replicas（可用副本）。当我们其中某一个Eureka Server 死掉的时候，unavailable-replicas就会有死掉的是哪一个Eureka Server，根据这个，我们就可以快速的重启对应的Eureka Server。 通常情况下是，启动两个注册中心c1和c2，但是在c1注册中心的available-replicas项中没有c2存在，反而是unavailable-replicas中有。 加入的配置为： 12345# 1、默认即可，源码中，这两个配置均为 trueregister-with-eureka: truefetch-registry: true# 2、eureka.client.serviceUrl.defaultZone配置项的地址，不能使用localhost，要使用service-center-1之类的域名，通过host映射到127.0.0.1；这里使用的是peer1、peer2、peer3# 3、spring.application.name或eureka.instance.appname必须一致； 现在我们将peer2 的Eureka Server 死掉，再看情况 我们可以看到 http://peer2:9101/eureka/ 出现在 unavailable-replicas，在我们的注册区EUREKA-SERVER 中也只有两个Eureka Server。 创建“服务提供方”创建提供支付服务的为服务模块，并向服务注册中心注册 创建一个名叫Pay Server 的Spring Boot 服务模块，在pom.xml 引入如下配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.geeur&lt;/groupId&gt; &lt;artifactId&gt;pay-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;pay-server&lt;/name&gt; &lt;description&gt;pay-server&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.M9&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 断路器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;weixin-server&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 然后在主应用类上加上@EnableDiscoveryClient注解，该注解能激活Eureka中的DiscoveryClient实现，才能实现Controller中对服务信息的输出。 1234567891011/** * 把 @SpringBootApplication 修改为 @SpringCloudApplication * 此注解中已经包含了 @EnableDiscoveryClient 注解 */@SpringCloudApplicationpublic class PayServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(PayServerApplication.class, args); &#125;&#125; 接下来就是application.yml 的配置(默认创建项目时生成的是application.properties 文件) 1234567891011121314server: port: 9200eureka: client: service-url: # 指定服务注册中心的位置（这里指定集群中的一个就可以） defaultZone: http://peer1:9100/eureka/ instance: instanceId: $&#123;spring.application.name&#125;:$&#123;server.port&#125; prefer-ip-address: falsespring: application: # 微服务名称，后续在调用的时候只需要使用该名称就可以进行服务的访问 name: pay-server 启动Pay Server 项目，访问我们的http://peer1:9100，显示如下图： 我们可以看到我们的服务中心已经注册了Pay Server，现在我们将 peer1的Eureka Server杀掉，为什么杀掉它，因为我们的Pay Server 中，defaultZone是向http://peer1:9100/eureka/注册的。显示如下图： 可以看到，我们的unavailable-replicas 中出现了http://peer1:9100/eureka/，但是我们的注册区任然是存在Pay Server 这个服务的。","tags":[{"name":"Eureka","slug":"Eureka","permalink":"http://blog.pcluo.com/tags/Eureka/"}]},{"title":"HashMap和HashSet实现原理","date":"2018-05-03T08:50:57.000Z","path":"2018/05/03/HashMap和HashSet实现原理/","text":"HashMap分析前言HashMap的数据结构：HashMap的数据结构是：数组 + 单向链表 的形式。 1、我们先从new HashMap();这里开始分析HashMap。进入源码分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; /** * The default initial capacity - MUST be a power of two. * 初始化时默认的HashMap容量, 必须为2的次幂值。 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. * 默认的HashMap最大的容量, 用以限制参数及表格最大容量, 必须是&lt;= 1&lt;&lt;30的2的次幂。 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * The load factor used when none specified in constructor. * 默认加载因子, 在构造的时候没有给定的情况下 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. * 由链表转换成树的阈值TREEIFY_THRESHOLD（链表转树） * 一个桶中bin（箱子）的存储方式由链表转换成树的阈值。即当桶中bin的数量超过TREEIFY_THRESHOLD时使用树来代替链表。默认值是8 */ static final int TREEIFY_THRESHOLD = 8; /** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. * 由树转换成链表的阈值UNTREEIFY_THRESHOLD（树转链表） * 当执行resize操作时，当桶中bin的数量少于UNTREEIFY_THRESHOLD时使用链表来代替树。默认值是6 */ static final int UNTREEIFY_THRESHOLD = 6; /** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. * 当桶中的bin被树化时最小的hash表容量。（如果没有达到这个阈值，即hash表容量小于MIN_TREEIFY_CAPACITY，当桶中bin的数量太多时会执行resize扩容操作）这个MIN_TREEIFY_CAPACITY的值至少是TREEIFY_THRESHOLD的4倍。 */ static final int MIN_TREEIFY_CAPACITY = 64; /** * The next size value at which to resize (capacity * load factor). * 表示当HashMap的size大于threshold时会执行resize操作 * @serial */ int threshold; /** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) * HashMap 存放的Node&lt;K,V&gt;[] */ transient Node&lt;K,V&gt;[] table;&#125; 这里我们来看一下 HashMap的四个构造方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity 初始容量值 * @param loadFactor the load factor 加载因子值 * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */public HashMap(int initialCapacity, float loadFactor) &#123; //如果传入的容量大小小于0，抛出IllegalArgumentException 异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); //如果传入的容量大小大于最大的容量，则修改成最大的容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //加载因子，小于0 或者 不是Float，抛出IllegalArgumentException 异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. 初始容量值 * @throws IllegalArgumentException if the initial capacity is negative. */public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;/** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 我们重点关注前面三个，通常我们直接用的是new HashMap();这一个构造器。可以看到这个构造器只有初始化loadFactor（加载因子） 这个变量。在来看 HashMap(int initialCapacity)，此构造函数调用HashMap(int initialCapacity, float loadFactor)这一个构造函数，我们来看一下这个构造函数的最后一行代码，看下他的实现this.threshold = tableSizeFor(initialCapacity);，这里也就是设置HashMap扩容的闸阀。当后续操作不断的增加HashMap的容量时，超过this.threshold值时，HashMap进行扩容。 12345678910111213/** * Returns a power of two size for the given target capacity. * 输出不小于cap的第一个2的n次幂，作为threshold，比如cap = 3，就变成了4 */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 2、HashMap存放值我们再来看HashMap.put()方法，跟着里面的注释进行分析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V put(K key, V value) &#123; //hash(key) 做hash处理，得到key对应的hash值 return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //这里table 通常情况下第一次put值时为null，除非在创建HashMap 的时候使用的是 HashMap(Map&lt;? extends K, ? extends V&gt; m)这一个构造器。 if ((tab = table) == null || (n = tab.length) == 0) //初始化table 或者给table 扩容 n = (tab = resize()).length; //i = (n - 1) &amp; hash：根据数组的大小，以及key 的hash 值，确定放入在tab数组中的位置。 //判断tab数组中，该位置是否为空。 //(n - 1) &amp; hash 决定当前的key 在tab 中的位置，这里也是为什么我们的容量必须是2的幂 (n - 1) &amp; hash 相当于 hash % (n-1) ，得到的值必定在 0 - (n-1) 之间，n又等于tab[] 的size，(n - 1) &amp; hash运算效率又极其之高。 if ((p = tab[i = (n - 1) &amp; hash]) == null) //为空，创建一个新的Node&lt;key, value&gt;，并赋值给tab[i] tab[i] = newNode(hash, key, value, null); else &#123; //不为空处理 Node&lt;K,V&gt; e; K k; //判断tab[i] 中 key 是否与put 进来的key 相同，这里使用hash和equals来进行比对 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //相同的情况下将p(tab[i]) 赋值给 e 即 tab[i]-&gt;p e-&gt;p e = p; else if (p instanceof TreeNode) //tab[i] 中 key 是与put 进来的key 不相同，且此时我们的Node 链表转化为 TreeNode链表了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //tab[i] 中 key 是与put 进来的key 不相同 for (int binCount = 0; ; ++binCount) &#123; //将p(tab[i])的下一个节点Node 赋值给e，判断e是不是为null if ((e = p.next) == null) &#123; //e == null 创建Node，将p(tab[i])指向新的Node（put 进来的key、value），并且结束循环 p.next = newNode(hash, key, value, null); //如果此时新加入的元素，造成了链表过大，将链表Node 转化为 TreeNode if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //判断e(p.next)的 key 是与put 进来的key 相同，相同则结束循环，不同将p -&gt; e，再次循环判断 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // p -&gt; e p = e; &#125; &#125; //判断e != null，即此时put 的值，在原来的tab 中已经存在，这里也就是将新的value 替换原有的value。 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) //tab 扩容 resize(); afterNodeInsertion(evict); return null;&#125;/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //将旧表中的数据复制给新表中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 可以看到，这里的分析的很多，那我们中点来看这一段代码： 12345678910111213141516171819202122232425262728293031323334353637//不为空处理Node&lt;K,V&gt; e; K k;//判断tab[i] 中 key 是否与put 进来的key 相同，这里使用hash和equals来进行比对if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //相同的情况下将p(tab[i]) 赋值给 e 即 tab[i]-&gt;p e-&gt;p e = p;else if (p instanceof TreeNode) //tab[i] 中 key 是与put 进来的key 不相同，且此时我们的Node 链表转化为 TreeNode链表了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);else &#123; //tab[i] 中 key 是与put 进来的key 不相同 for (int binCount = 0; ; ++binCount) &#123; //将p(tab[i])的下一个节点Node 赋值给e，判断e是不是为null if ((e = p.next) == null) &#123; //e == null 创建Node，将p.next(tab[i].next)指向新的Node（put 进来的key、value），并且结束循环，这里其实就是把p.next(tab[i].next)指向新的Node p.next = newNode(hash, key, value, null); //如果此时新加入的元素，造成了链表过大，将链表Node 转化为 TreeNode if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //判断e(p.next)的 key 是与put 进来的key 相同，相同则结束循环，不同将p -&gt; e，再次循环判断 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // p -&gt; e p = e; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; p -&gt; tab[i]，我们put 一个值到tab[i] 位置上，此时tab[i] 已经存在值。 当我们put 一个值时，首先会判断 put 的 key 是否与tab[i] 中的key 相同。相同 e -&gt; p，跳出if else，向下执行。不相同，判断当前的p 是否为 TreeNode类型，不为TreeNode 类型，执行else，进入for循环。重点来了。 if ((e = p.next) == null)首先将p.next赋给e并判断是否为null，如果为空（此时tab[i]中，有且仅有一个Node），创建一个新的Node 赋值给p.next，在判断此时 tab[i]链表中的Node 数量是否超过闸阀 TREEIFY_THRESHOLD，超过则把Node类型 转换为 TreeNode类型。跳出循环。（因为e = p.next为null，所以if (e != null)下面不再执行） if ((e = p.next) == null)首先将p.next赋给e并判断是否为null，如果不为空（此时tab[i]中，存在2个以上Node或TreeNode），我们看if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))，因为我们之前只检验了我们put 进来的值 与tab[i] 上的这个值是否相同，那后面的链表中，所有的值都要进行检验是否相同。如果相同，直接跳出循环，进入if (e != null)继续执行。将新put 进来的 value 替换 oldValue。如果校验不相同，则p = e，继续进行循环，如果所有的Node 的key 与新put 的key 都不同的话，则把新put 的值放在链表结尾。 当put 完之后，进行判断if (++size &gt; threshold)，是否需要对HashMap 进行扩容。 3、HashMap取值我们再来看HashMap.get()方法，跟着里面的注释进行分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Returns the value to which the specified key is mapped, * or &#123;@code null&#125; if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code (key==null ? k==null : * key.equals(k))&#125;, then this method returns &#123;@code v&#125;; otherwise * it returns &#123;@code null&#125;. (There can be at most one such mapping.) * * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to &#123;@code null&#125;. * The &#123;@link #containsKey containsKey&#125; operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //判断 table 是否为 null，或者table.length 是不是大于0，并且tab[(n - 1) &amp; hash] 对应的值不能为null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //判断第一个 Node(first) 的 key 是否与 传入的 key 相同，相同直接返回 first if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //判断下一个Node 是否为 null if ((e = first.next) != null) &#123; //判断是否为TreeNode 类型 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //执行循环 判断当前的Node(e) 的 key 是否与 传入的 key 相同，相同直接返回 e，不相同，判断(e = e.next) != null。继续执行，如果最后没有找到，直接返回null if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 这里我们看以看到HashMap.get()的思路跟HashMap.put()的思路是一样的。都是通过比较 key 的 hash值 和 equals 来看 可以是否 key 相同。首先找到key 的hash 在table[] 中的位置，匹对table[i] 的key 是否与 get 的 key相同，不相同，寻找table[i] 的下一个节点Node，对整个链表进行遍历。找到则取出，没有找到继续遍历，直到整个链表遍历完成，若遍历完成之后还未找到，则返回null。 4、HashMap的工作原理HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到table位置来储存Entry对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//put 中加入新Node newNode(hash, key, value, null);Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next);&#125;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 5、HashMap注意事项 减少”碰撞”发生，经过我们的源码分析。一旦发生key的 hash值碰撞，就会在”碰撞”位置开始对整个链表遍历，链表的遍历会带来效率的影响。通常我们使用String，Interger这样的wrapper类作为HashMap 的key。或者使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法，来减少碰撞的发生。 避免扩容，在resize()方法中，我们可以看下是怎么扩容的。关键代码： 1234567891011if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //通常执行这里，newCap = oldCap &lt;&lt; 1 也就是扩大一倍原来的容量 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold&#125;Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; 这个开销是非常大的，在table[] 数组中扩容。扩容之后，还要把oldTab 中的数据复制到 newTab中。在我们使用HashMap 的时候尽可能的估算map 的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容 。 不能在多线程中使用HashMap，HashMap是非线程安全的。在扩容的时候，HashMap可能造成死循环。 负载因子可以进行修改，但不建议去修改，因为这个是经过科学计算得出的一个值，除非特殊情况下。 HashSet分析上面我们分析了HashMap，为什么我们先分析HashMap 呢？直接进入主题，这里我们列出部分代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; private transient HashMap&lt;E,Object&gt; map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * default initial capacity (16) and load factor (0.75). */ public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; /** * Constructs a new set containing the elements in the specified * collection. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with default load factor * (0.75) and an initial capacity sufficient to contain the elements in * the specified collection. * * @param c the collection whose elements are to be placed into this set * @throws NullPointerException if the specified collection is null */ public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125; /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and the specified load factor. * * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */ public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor); &#125; /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and default load factor (0.75). * * @param initialCapacity the initial capacity of the hash table * @throws IllegalArgumentException if the initial capacity is less * than zero */ public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity); &#125; /** * Constructs a new, empty linked hash set. (This package private * constructor is only used by LinkedHashSet.) The backing * HashMap instance is a LinkedHashMap with the specified initial * capacity and the specified load factor. * * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @param dummy ignored (distinguishes this * constructor from other int, float constructor.) * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */ HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125;&#125; 可以看到，我们的HashSet在构造的时候，都会实例一个HashMap。 再来看HashSet.add方法： 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 可以看到实际上是map.put(e, PRESENT)，用的是HashMap 的put 方法。对象作为key，new Object()作为值存放到map 中。 由此可知，HashSet 的原理跟HashMap 的原理是差不多的。 HashSet 取值： 123456789101112/** * 返回对此set中元素进行迭代的迭代器。返回元素的顺序并不是特定的。 * * 底层实际调用底层HashMap的keySet来返回所有的key。 * 可见HashSet中的元素，只是存放在了底层HashMap的key上， * value使用一个static final的Object对象标识。 * @return 对此set中元素进行迭代的Iterator。 */ public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125;//通过迭代器遍历获取值 HsahSet是基于HashMap 实现的，默认构造函数是构建一个初始容量为16，负载因子为0.75 的HashMap。封装了一个 HashMap 对象来存储所有的集合元素，所有放入 HashSet 中的集合元素实际上由 HashMap 的 key 来保存，而 HashMap 的 value 则存储了一个 PRESENT，它是一个静态的 Object 对象。 当我们试图把某个类的对象当成 HashMap的 key，或试图将这个类的对象放入 HashSet 中保存时，重写该类的equals(Object obj)方法和 hashCode() 方法很重要，而且这两个方法的返回值必须保持一致：当该类的两个的 hashCode() 返回值相同时，它们通过 equals() 方法比较也应该返回 true。通常来说，所有参与计算 hashCode() 返回值的关键属性，都应该用于作为 equals() 比较的标准。","tags":[{"name":"HashMap HashSet","slug":"HashMap-HashSet","permalink":"http://blog.pcluo.com/tags/HashMap-HashSet/"}]},{"title":"Servlet 生命周期","date":"2018-05-03T06:00:33.000Z","path":"2018/05/03/Servlet 生命周期/","text":"一个Servlrt 的生命周期可以被定义为从创建到销毁的整个过程。以下是Servlrt 所遵循的路径，我们先看下Servlet 有哪些方法，中点关注那些方法（init()、service()、destroy()） Servlrt 的生命周期分为三个阶段： 1、初始化阶段1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465类加载器加载Servlet --&gt; 容器创建Servlet --&gt; 容器调用Servlet.init()Servlet.init()只会被调用一次，它只在Servlet 创建的时候调用，之后的任何用户请求都不会在被调用。这里在Servlet 创建并初始化的时候，tomcat 会把它放到容器的缓存中来进行管理，在下一次访问的时候看缓存中是否有这个Servlet，如果有则直接拿出来调用。默认情况下Servlet 是什么时候被创建的呢? 我们在web.xml 里面配置我们的Servlet 代码如下 &lt;servlet&gt; &lt;!-- servlet的内部名称，自定义。尽量有意义 --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的类全名： 包名+简单类名 --&gt; &lt;servlet-class&gt;com.blog.demo.servlet.DefaultServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;!-- servlet的映射配置 --&gt; &lt;servlet-mapping&gt; &lt;!-- servlet的内部名称，一定要和上面的内部名称保持一致！！ --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的映射路径（访问servlet的名称） --&gt; &lt;url-pattern&gt;/servlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; Servlet public class DefaultServlet extends HttpServlet &#123; public DefaultServlet() &#123; System.out.println(\"DefaultServlet construct\"); &#125; @Override public void init() throws ServletException &#123; System.out.println(\"DefaultServlet init\"); super.init(); &#125; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(\"DefaultServlet doGet\"); super.doGet(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(\"DefaultServlet doPost\"); super.doPost(req, resp); &#125; @Override public void destroy() &#123; System.out.println(\"DefaultServlet destroy\"); super.destroy(); &#125;&#125;此时我们启动我们的容器，这里以tomcat容器为例，启动我们的tomcat 查看启动日志，我们并没有发现控制台有打印 DefaultServlet init，这是我们访问一下我们的Servlet doGet方法我们看打印的日志DefaultServlet constructDefaultServlet initDefaultServlet doGet即Servlet 在我们访问的时候被创建，并且初始化，之后再次调用不再调用Servlet.init()方法。第一次调用Servlet.doGet()的方法时，tomcat 会判断容器中是否有这个Servlet 的实例，如果有则直接调用Servlet.doGet()，如果没有则创建Servlet 并调用 init 方法。之后再次访问就不再调用Servlet.init()日志如下图： 1234567891011121314151617通常我们会在 web.xml Servlet 配置里面加上 &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; 这样一个配置，这个配置的作用就是告诉web容器(tomcat) 在容器启动时就加载这个Servlet，现在我们把这个配置加上，然后再启动web容器，我们发现tomcat 在启动时就帮我们创建了Servlet 并且初始化 &lt;servlet&gt; &lt;!-- servlet的内部名称，自定义。尽量有意义 --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的类全名： 包名+简单类名 --&gt; &lt;servlet-class&gt;com.blog.demo.servlet.DefaultServlet&lt;/servlet-class&gt; &lt;!-- 默认容器启动时创建Servlet --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- servlet的映射配置 --&gt; &lt;servlet-mapping&gt; &lt;!-- servlet的内部名称，一定要和上面的内部名称保持一致！！ --&gt; &lt;servlet-name&gt;defaultServlet&lt;/servlet-name&gt; &lt;!-- servlet的映射路径（访问servlet的名称） --&gt; &lt;url-pattern&gt;/servlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 2、相应客户端请求阶段12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Servlet 在创建好之后，就处于响应就绪状态，只要有请求过来就会执行Servlet.service()。为什么我们在上面直接说请求Servlet.doGet()方法呢？以下是HttpServlet 对service 的处理public abstract class HttpServlet extends GenericServlet implements Serializable &#123; public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; HttpServletRequest request; HttpServletResponse response; try &#123; request = (HttpServletRequest)req; response = (HttpServletResponse)res; &#125; catch (ClassCastException var6) &#123; throw new ServletException(\"non-HTTP request or response\"); &#125; this.service(request, response); &#125; protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); long lastModified; if (method.equals(\"GET\")) &#123; lastModified = this.getLastModified(req); if (lastModified == -1L) &#123; this.doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(\"If-Modified-Since\"); if (ifModifiedSince &lt; lastModified / 1000L * 1000L) &#123; this.maybeSetLastModified(resp, lastModified); this.doGet(req, resp); &#125; else &#123; resp.setStatus(304); &#125; &#125; &#125; else if (method.equals(\"HEAD\")) &#123; lastModified = this.getLastModified(req); this.maybeSetLastModified(resp, lastModified); this.doHead(req, resp); &#125; else if (method.equals(\"POST\")) &#123; this.doPost(req, resp); &#125; else if (method.equals(\"PUT\")) &#123; this.doPut(req, resp); &#125; else if (method.equals(\"DELETE\")) &#123; this.doDelete(req, resp); &#125; else if (method.equals(\"OPTIONS\")) &#123; this.doOptions(req, resp); &#125; else if (method.equals(\"TRACE\")) &#123; this.doTrace(req, resp); &#125; else &#123; String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[]&#123;method&#125;; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(501, errMsg); &#125; &#125;&#125;通过HttpServlet 的源码，我们知道在调用service 方法的时候，它会根据请求类型，调用自身的对应的 doGet，doPost，doPut，doDelete ...等方法所以我们在自定义的时候只要Override 这些方法即可。当请求过来的时候，web容器会创建一个新的线程来处理这个请求，web容器来调用对应Servlet.service()，方法Servlet.service()根据请求调用doGet、doPost等方法并完成请求响应，之后线程结束，请求结束。 3、销毁阶段123web容器销毁阶段，会调用应用中所有的Servlet.destroy()。该方法在整个生命周期也是只被调用一次，在Servlet 被销毁的时候，此时我们可以释放掉Servlet 所占用的资源。例如关闭与数据库的连接。下图是容器销毁时调用","tags":[{"name":"源码分析之Servlet","slug":"源码分析之Servlet","permalink":"http://blog.pcluo.com/tags/源码分析之Servlet/"}]},{"title":"博客搭建","date":"2018-03-27T03:15:00.000Z","path":"2018/03/27/博客快速搭建/","text":"快速搭建参看网址搭建 参看网址多机使用 Create a new post and commit1234567cd 你的博客目录$ hexo new \"My New Post\" // /你的博客目录/source/_posts/My New Post.mdgit commit -am 'add My New Post.md and commit'git pushhexo clean // 先进行cleanhexo d -g // 更新到master分支","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://blog.pcluo.com/tags/博客搭建/"}]}]